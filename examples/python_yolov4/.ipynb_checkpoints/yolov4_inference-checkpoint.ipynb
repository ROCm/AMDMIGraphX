{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with YoloV4\n",
    "This notebook is intended to be an example of how to use MIGraphX to perform object detection. The model used below is a pre-trained yolov4 from the ONNX model zoo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-13 12:33:32--  https://farm3.staticflickr.com/2009/2306189268_88cc86b30f_z.jpg\n",
      "Resolving farm3.staticflickr.com (farm3.staticflickr.com)... 13.226.180.96, 2600:9000:2031:4200:0:5a51:64c9:c681, 2600:9000:2031:ba00:0:5a51:64c9:c681, ...\n",
      "Connecting to farm3.staticflickr.com (farm3.staticflickr.com)|13.226.180.96|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [image/jpeg]\n",
      "Saving to: ‘input.jpg’\n",
      "\n",
      "input.jpg               [ <=>                ] 103.24K  --.-KB/s    in 0.09s   \n",
      "\n",
      "2021-05-13 12:33:33 (1.08 MB/s) - ‘input.jpg’ saved [105718]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "if not path.exists(\"coco.names\"):\n",
    "    !wget https://github.com/onnx/models/raw/master/vision/object_detection_segmentation/yolov4/dependencies/coco.names\n",
    "if not path.exists(\"yolov4_anchors.txt\"):\n",
    "    !wget https://github.com/onnx/models/raw/master/vision/object_detection_segmentation/yolov4/dependencies/yolov4_anchors.txt\n",
    "if not path.exists(\"input.jpg\"):\n",
    "    # The image used is from the COCO dataset (https://cocodataset.org/#explore)\n",
    "    # Other images can be tested by replacing the link below\n",
    "    image_link = \"https://farm3.staticflickr.com/2009/2306189268_88cc86b30f_z.jpg\"\n",
    "    !wget -O input.jpg $image_link\n",
    "if not path.exists(\"yolov4.onnx\"):\n",
    "    !wget https://github.com/onnx/models/raw/master/vision/object_detection_segmentation/yolov4/model/yolov4.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize model using model optimizer tool\n",
    "Please refer to the [model optimizer example](../python_model_optimizer/README.md) if you would like more information about this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists(\"yolov4_fp16.msgpack\"):\n",
    "    !python3 ../python_model_optimizer/optimize_model.py -t gpu -f -p ../python_yolov4/yolov4_fp16 ../python_yolov4/yolov4.onnx\n",
    "if not path.exists(\"yolov4.msgpack\"):\n",
    "    !python3 ../python_model_optimizer/optimize_model.py -t gpu -p ../python_yolov4/ ../python_yolov4/yolov4.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries \n",
    "Please refer to [this section](https://github.com/ROCmSoftwarePlatform/AMDMIGraphX#using-migraphx-python-module) of the main README if the migraphx module is not found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import migraphx\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import image_processing as ip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and pre-process image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 416\n",
    "\n",
    "original_image = cv2.imread(\"input.jpg\")\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "original_image_size = original_image.shape[:2]\n",
    "\n",
    "image_data = ip.image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "image_data = image_data[np.newaxis, ...].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load serialized model (either single- or half-precision)\n",
    "model = migraphx.load(\"yolov4_fp16.msgpack\", format=\"msgpack\")\n",
    "\n",
    "# Get the name of the input parameter and convert image data to an MIGraphX argument\n",
    "input_name = next(iter(model.get_parameter_shapes()))\n",
    "input_argument = migraphx.argument(image_data)\n",
    "\n",
    "# Evaluate the model and convert the outputs for post-processing\n",
    "outputs = model.run({input_name: input_argument})\n",
    "detections = [np.ndarray(shape=out.get_shape().lens(), buffer=np.array(out.tolist()), dtype=float) for out in outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process the model outputs and display image with detection bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHORS = \"./yolov4_anchors.txt\"\n",
    "STRIDES = [8, 16, 32]\n",
    "XYSCALE = [1.2, 1.1, 1.05]\n",
    "\n",
    "ANCHORS = ip.get_anchors(ANCHORS)\n",
    "STRIDES = np.array(STRIDES)\n",
    "\n",
    "pred_bbox = ip.postprocess_bbbox(detections, ANCHORS, STRIDES, XYSCALE)\n",
    "bboxes = ip.postprocess_boxes(pred_bbox, original_image_size, input_size, 0.25)\n",
    "bboxes = ip.nms(bboxes, 0.213, method='nms')\n",
    "image = ip.draw_bbox(original_image, bboxes)\n",
    "\n",
    "image = Image.fromarray(image)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python383jvsc74a57bd0d7283edef085bb46d38a3069bce96b3de1793019cb5bd7b1e86bf9785b67f304"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "d7283edef085bb46d38a3069bce96b3de1793019cb5bd7b1e86bf9785b67f304"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
