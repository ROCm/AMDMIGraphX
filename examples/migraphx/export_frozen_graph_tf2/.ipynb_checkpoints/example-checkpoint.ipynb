{
 "cells": [
	{
		"cell_type": "code",
		"metadata": {},
		"source": [
			"#  The MIT License (MIT)",
			"#",
			"#  Copyright (c) 2015-2022 Advanced Micro Devices, Inc. All rights reserved.",
			"#",
			"#  Permission is hereby granted, free of charge, to any person obtaining a copy",
			"#  of this software and associated documentation files (the 'Software'), to deal",
			"#  in the Software without restriction, including without limitation the rights",
			"#  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell",
			"#  copies of the Software, and to permit persons to whom the Software is",
			"#  furnished to do so, subject to the following conditions:",
			"#",
			"#  The above copyright notice and this permission notice shall be included in",
			"#  all copies or substantial portions of the Software.",
			"#",
			"#  THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR",
			"#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,",
			"#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE",
			"#  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER",
			"#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,",
			"#  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN",
			"#  THE SOFTWARE."
		]
	},

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Frozen Graphs in Tensorflow 2 \n",
    "In order to use a trained model as input to MIGraphX, the model must be first be saved in a frozen graph format. This was accomplished in Tensorflow 1 by launching a graph in a tf.Session and then saving the session. However, Tensorflow has decided to deprecate Sessions in favor of functions and SavedModel format.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the necessary libraries, the next step is to instantiate a model. For simplicity, in this example we will use a resnet50 architecture with pre-trained imagenet weights. These weights may also be trained or fine-tuned before freezing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution() #May not be required depending on tensorflow version\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "MODEL_NAME = \"resnet50\"\n",
    "model = tf.keras.applications.ResNet50(weights=\"imagenet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SavedModel format\n",
    "The simplest way to save a model is through saved\\_model.save()\n",
    "\n",
    "This will create an equivalent tensorflow program which can later be loaded for fine-tuning or inference, although it is not directly compatible with MIGraphX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./Saved_Models/resnet50/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"./Saved_Models/{}\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to ConcreteFunction\n",
    "To begin, we need to get the function equivalent of the model and then concretize the function to avoid retracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = tf.function(lambda x: model(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze ConcreteFunction and Serialize\n",
    "Since we are saving the graph for the purpose of inference, all variables can be made constant (i.e. \"frozen\").\n",
    "\n",
    "Next, we need to obtain a serialized GraphDef representation of the graph. \n",
    "\n",
    "\n",
    "Optionally, the operators can be printed out layer by layer followed by the inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "resnet50/conv1_pad/Pad/paddings\n",
      "resnet50/conv1_pad/Pad\n",
      "resnet50/conv1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv1_conv/Conv2D\n",
      "resnet50/conv1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv1_conv/BiasAdd\n",
      "resnet50/conv1_bn/ReadVariableOp/resource\n",
      "resnet50/conv1_bn/ReadVariableOp\n",
      "resnet50/conv1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv1_bn/ReadVariableOp_1\n",
      "resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv1_bn/FusedBatchNormV3\n",
      "resnet50/conv1_relu/Relu\n",
      "resnet50/pool1_pad/Pad/paddings\n",
      "resnet50/pool1_pad/Pad\n",
      "resnet50/pool1_pool/MaxPool\n",
      "resnet50/conv2_block1_0_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_0_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block1_0_conv/Conv2D\n",
      "resnet50/conv2_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block1_0_conv/BiasAdd\n",
      "resnet50/conv2_block1_0_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_0_bn/ReadVariableOp\n",
      "resnet50/conv2_block1_0_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_0_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block1_0_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block1_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block1_1_conv/Conv2D\n",
      "resnet50/conv2_block1_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block1_1_conv/BiasAdd\n",
      "resnet50/conv2_block1_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_1_bn/ReadVariableOp\n",
      "resnet50/conv2_block1_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_1_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block1_1_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block1_1_relu/Relu\n",
      "resnet50/conv2_block1_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block1_2_conv/Conv2D\n",
      "resnet50/conv2_block1_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block1_2_conv/BiasAdd\n",
      "resnet50/conv2_block1_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_2_bn/ReadVariableOp\n",
      "resnet50/conv2_block1_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_2_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block1_2_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block1_2_relu/Relu\n",
      "resnet50/conv2_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block1_3_conv/Conv2D\n",
      "resnet50/conv2_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block1_3_conv/BiasAdd\n",
      "resnet50/conv2_block1_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_3_bn/ReadVariableOp\n",
      "resnet50/conv2_block1_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_3_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block1_3_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block1_add/add\n",
      "resnet50/conv2_block1_out/Relu\n",
      "resnet50/conv2_block2_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block2_1_conv/Conv2D\n",
      "resnet50/conv2_block2_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block2_1_conv/BiasAdd\n",
      "resnet50/conv2_block2_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_1_bn/ReadVariableOp\n",
      "resnet50/conv2_block2_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block2_1_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block2_1_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block2_1_relu/Relu\n",
      "resnet50/conv2_block2_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block2_2_conv/Conv2D\n",
      "resnet50/conv2_block2_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block2_2_conv/BiasAdd\n",
      "resnet50/conv2_block2_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_2_bn/ReadVariableOp\n",
      "resnet50/conv2_block2_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block2_2_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block2_2_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block2_2_relu/Relu\n",
      "resnet50/conv2_block2_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block2_3_conv/Conv2D\n",
      "resnet50/conv2_block2_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block2_3_conv/BiasAdd\n",
      "resnet50/conv2_block2_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_3_bn/ReadVariableOp\n",
      "resnet50/conv2_block2_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block2_3_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block2_3_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block2_add/add\n",
      "resnet50/conv2_block2_out/Relu\n",
      "resnet50/conv2_block3_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block3_1_conv/Conv2D\n",
      "resnet50/conv2_block3_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block3_1_conv/BiasAdd\n",
      "resnet50/conv2_block3_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_1_bn/ReadVariableOp\n",
      "resnet50/conv2_block3_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block3_1_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block3_1_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block3_1_relu/Relu\n",
      "resnet50/conv2_block3_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block3_2_conv/Conv2D\n",
      "resnet50/conv2_block3_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block3_2_conv/BiasAdd\n",
      "resnet50/conv2_block3_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_2_bn/ReadVariableOp\n",
      "resnet50/conv2_block3_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block3_2_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block3_2_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block3_2_relu/Relu\n",
      "resnet50/conv2_block3_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv2_block3_3_conv/Conv2D\n",
      "resnet50/conv2_block3_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv2_block3_3_conv/BiasAdd\n",
      "resnet50/conv2_block3_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_3_bn/ReadVariableOp\n",
      "resnet50/conv2_block3_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block3_3_bn/ReadVariableOp_1\n",
      "resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv2_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv2_block3_3_bn/FusedBatchNormV3\n",
      "resnet50/conv2_block3_add/add\n",
      "resnet50/conv2_block3_out/Relu\n",
      "resnet50/conv3_block1_0_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_0_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block1_0_conv/Conv2D\n",
      "resnet50/conv3_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block1_0_conv/BiasAdd\n",
      "resnet50/conv3_block1_0_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_0_bn/ReadVariableOp\n",
      "resnet50/conv3_block1_0_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_0_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block1_0_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block1_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block1_1_conv/Conv2D\n",
      "resnet50/conv3_block1_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block1_1_conv/BiasAdd\n",
      "resnet50/conv3_block1_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_1_bn/ReadVariableOp\n",
      "resnet50/conv3_block1_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_1_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block1_1_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block1_1_relu/Relu\n",
      "resnet50/conv3_block1_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block1_2_conv/Conv2D\n",
      "resnet50/conv3_block1_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block1_2_conv/BiasAdd\n",
      "resnet50/conv3_block1_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_2_bn/ReadVariableOp\n",
      "resnet50/conv3_block1_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_2_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block1_2_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block1_2_relu/Relu\n",
      "resnet50/conv3_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block1_3_conv/Conv2D\n",
      "resnet50/conv3_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block1_3_conv/BiasAdd\n",
      "resnet50/conv3_block1_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_3_bn/ReadVariableOp\n",
      "resnet50/conv3_block1_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_3_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block1_3_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block1_add/add\n",
      "resnet50/conv3_block1_out/Relu\n",
      "resnet50/conv3_block2_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block2_1_conv/Conv2D\n",
      "resnet50/conv3_block2_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block2_1_conv/BiasAdd\n",
      "resnet50/conv3_block2_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_1_bn/ReadVariableOp\n",
      "resnet50/conv3_block2_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block2_1_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block2_1_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block2_1_relu/Relu\n",
      "resnet50/conv3_block2_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block2_2_conv/Conv2D\n",
      "resnet50/conv3_block2_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block2_2_conv/BiasAdd\n",
      "resnet50/conv3_block2_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_2_bn/ReadVariableOp\n",
      "resnet50/conv3_block2_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block2_2_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block2_2_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block2_2_relu/Relu\n",
      "resnet50/conv3_block2_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block2_3_conv/Conv2D\n",
      "resnet50/conv3_block2_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block2_3_conv/BiasAdd\n",
      "resnet50/conv3_block2_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_3_bn/ReadVariableOp\n",
      "resnet50/conv3_block2_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block2_3_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block2_3_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block2_add/add\n",
      "resnet50/conv3_block2_out/Relu\n",
      "resnet50/conv3_block3_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block3_1_conv/Conv2D\n",
      "resnet50/conv3_block3_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block3_1_conv/BiasAdd\n",
      "resnet50/conv3_block3_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_1_bn/ReadVariableOp\n",
      "resnet50/conv3_block3_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block3_1_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block3_1_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block3_1_relu/Relu\n",
      "resnet50/conv3_block3_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block3_2_conv/Conv2D\n",
      "resnet50/conv3_block3_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block3_2_conv/BiasAdd\n",
      "resnet50/conv3_block3_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_2_bn/ReadVariableOp\n",
      "resnet50/conv3_block3_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block3_2_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block3_2_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block3_2_relu/Relu\n",
      "resnet50/conv3_block3_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block3_3_conv/Conv2D\n",
      "resnet50/conv3_block3_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block3_3_conv/BiasAdd\n",
      "resnet50/conv3_block3_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_3_bn/ReadVariableOp\n",
      "resnet50/conv3_block3_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block3_3_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block3_3_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block3_add/add\n",
      "resnet50/conv3_block3_out/Relu\n",
      "resnet50/conv3_block4_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block4_1_conv/Conv2D\n",
      "resnet50/conv3_block4_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block4_1_conv/BiasAdd\n",
      "resnet50/conv3_block4_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_1_bn/ReadVariableOp\n",
      "resnet50/conv3_block4_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block4_1_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block4_1_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block4_1_relu/Relu\n",
      "resnet50/conv3_block4_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block4_2_conv/Conv2D\n",
      "resnet50/conv3_block4_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block4_2_conv/BiasAdd\n",
      "resnet50/conv3_block4_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_2_bn/ReadVariableOp\n",
      "resnet50/conv3_block4_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block4_2_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block4_2_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block4_2_relu/Relu\n",
      "resnet50/conv3_block4_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv3_block4_3_conv/Conv2D\n",
      "resnet50/conv3_block4_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv3_block4_3_conv/BiasAdd\n",
      "resnet50/conv3_block4_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_3_bn/ReadVariableOp\n",
      "resnet50/conv3_block4_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block4_3_bn/ReadVariableOp_1\n",
      "resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv3_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv3_block4_3_bn/FusedBatchNormV3\n",
      "resnet50/conv3_block4_add/add\n",
      "resnet50/conv3_block4_out/Relu\n",
      "resnet50/conv4_block1_0_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_0_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block1_0_conv/Conv2D\n",
      "resnet50/conv4_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block1_0_conv/BiasAdd\n",
      "resnet50/conv4_block1_0_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_0_bn/ReadVariableOp\n",
      "resnet50/conv4_block1_0_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_0_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block1_0_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block1_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block1_1_conv/Conv2D\n",
      "resnet50/conv4_block1_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block1_1_conv/BiasAdd\n",
      "resnet50/conv4_block1_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_1_bn/ReadVariableOp\n",
      "resnet50/conv4_block1_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_1_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block1_1_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block1_1_relu/Relu\n",
      "resnet50/conv4_block1_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block1_2_conv/Conv2D\n",
      "resnet50/conv4_block1_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block1_2_conv/BiasAdd\n",
      "resnet50/conv4_block1_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_2_bn/ReadVariableOp\n",
      "resnet50/conv4_block1_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_2_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block1_2_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block1_2_relu/Relu\n",
      "resnet50/conv4_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block1_3_conv/Conv2D\n",
      "resnet50/conv4_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block1_3_conv/BiasAdd\n",
      "resnet50/conv4_block1_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_3_bn/ReadVariableOp\n",
      "resnet50/conv4_block1_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_3_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block1_3_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block1_add/add\n",
      "resnet50/conv4_block1_out/Relu\n",
      "resnet50/conv4_block2_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block2_1_conv/Conv2D\n",
      "resnet50/conv4_block2_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block2_1_conv/BiasAdd\n",
      "resnet50/conv4_block2_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_1_bn/ReadVariableOp\n",
      "resnet50/conv4_block2_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block2_1_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block2_1_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block2_1_relu/Relu\n",
      "resnet50/conv4_block2_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block2_2_conv/Conv2D\n",
      "resnet50/conv4_block2_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block2_2_conv/BiasAdd\n",
      "resnet50/conv4_block2_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_2_bn/ReadVariableOp\n",
      "resnet50/conv4_block2_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block2_2_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block2_2_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block2_2_relu/Relu\n",
      "resnet50/conv4_block2_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block2_3_conv/Conv2D\n",
      "resnet50/conv4_block2_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block2_3_conv/BiasAdd\n",
      "resnet50/conv4_block2_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_3_bn/ReadVariableOp\n",
      "resnet50/conv4_block2_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block2_3_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block2_3_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block2_add/add\n",
      "resnet50/conv4_block2_out/Relu\n",
      "resnet50/conv4_block3_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block3_1_conv/Conv2D\n",
      "resnet50/conv4_block3_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block3_1_conv/BiasAdd\n",
      "resnet50/conv4_block3_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_1_bn/ReadVariableOp\n",
      "resnet50/conv4_block3_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block3_1_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block3_1_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block3_1_relu/Relu\n",
      "resnet50/conv4_block3_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block3_2_conv/Conv2D\n",
      "resnet50/conv4_block3_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block3_2_conv/BiasAdd\n",
      "resnet50/conv4_block3_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_2_bn/ReadVariableOp\n",
      "resnet50/conv4_block3_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block3_2_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block3_2_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block3_2_relu/Relu\n",
      "resnet50/conv4_block3_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block3_3_conv/Conv2D\n",
      "resnet50/conv4_block3_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block3_3_conv/BiasAdd\n",
      "resnet50/conv4_block3_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_3_bn/ReadVariableOp\n",
      "resnet50/conv4_block3_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block3_3_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block3_3_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block3_add/add\n",
      "resnet50/conv4_block3_out/Relu\n",
      "resnet50/conv4_block4_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block4_1_conv/Conv2D\n",
      "resnet50/conv4_block4_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block4_1_conv/BiasAdd\n",
      "resnet50/conv4_block4_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_1_bn/ReadVariableOp\n",
      "resnet50/conv4_block4_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block4_1_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block4_1_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block4_1_relu/Relu\n",
      "resnet50/conv4_block4_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block4_2_conv/Conv2D\n",
      "resnet50/conv4_block4_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block4_2_conv/BiasAdd\n",
      "resnet50/conv4_block4_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_2_bn/ReadVariableOp\n",
      "resnet50/conv4_block4_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block4_2_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block4_2_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block4_2_relu/Relu\n",
      "resnet50/conv4_block4_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block4_3_conv/Conv2D\n",
      "resnet50/conv4_block4_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block4_3_conv/BiasAdd\n",
      "resnet50/conv4_block4_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_3_bn/ReadVariableOp\n",
      "resnet50/conv4_block4_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block4_3_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block4_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block4_3_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block4_add/add\n",
      "resnet50/conv4_block4_out/Relu\n",
      "resnet50/conv4_block5_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block5_1_conv/Conv2D\n",
      "resnet50/conv4_block5_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block5_1_conv/BiasAdd\n",
      "resnet50/conv4_block5_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_1_bn/ReadVariableOp\n",
      "resnet50/conv4_block5_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block5_1_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block5_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block5_1_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block5_1_relu/Relu\n",
      "resnet50/conv4_block5_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block5_2_conv/Conv2D\n",
      "resnet50/conv4_block5_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block5_2_conv/BiasAdd\n",
      "resnet50/conv4_block5_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_2_bn/ReadVariableOp\n",
      "resnet50/conv4_block5_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block5_2_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block5_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block5_2_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block5_2_relu/Relu\n",
      "resnet50/conv4_block5_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block5_3_conv/Conv2D\n",
      "resnet50/conv4_block5_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block5_3_conv/BiasAdd\n",
      "resnet50/conv4_block5_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_3_bn/ReadVariableOp\n",
      "resnet50/conv4_block5_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block5_3_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block5_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block5_3_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block5_add/add\n",
      "resnet50/conv4_block5_out/Relu\n",
      "resnet50/conv4_block6_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block6_1_conv/Conv2D\n",
      "resnet50/conv4_block6_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block6_1_conv/BiasAdd\n",
      "resnet50/conv4_block6_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_1_bn/ReadVariableOp\n",
      "resnet50/conv4_block6_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block6_1_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block6_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block6_1_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block6_1_relu/Relu\n",
      "resnet50/conv4_block6_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block6_2_conv/Conv2D\n",
      "resnet50/conv4_block6_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block6_2_conv/BiasAdd\n",
      "resnet50/conv4_block6_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_2_bn/ReadVariableOp\n",
      "resnet50/conv4_block6_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block6_2_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block6_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block6_2_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block6_2_relu/Relu\n",
      "resnet50/conv4_block6_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv4_block6_3_conv/Conv2D\n",
      "resnet50/conv4_block6_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv4_block6_3_conv/BiasAdd\n",
      "resnet50/conv4_block6_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_3_bn/ReadVariableOp\n",
      "resnet50/conv4_block6_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block6_3_bn/ReadVariableOp_1\n",
      "resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv4_block6_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv4_block6_3_bn/FusedBatchNormV3\n",
      "resnet50/conv4_block6_add/add\n",
      "resnet50/conv4_block6_out/Relu\n",
      "resnet50/conv5_block1_0_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_0_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block1_0_conv/Conv2D\n",
      "resnet50/conv5_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block1_0_conv/BiasAdd\n",
      "resnet50/conv5_block1_0_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_0_bn/ReadVariableOp\n",
      "resnet50/conv5_block1_0_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_0_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_0_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block1_0_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block1_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block1_1_conv/Conv2D\n",
      "resnet50/conv5_block1_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block1_1_conv/BiasAdd\n",
      "resnet50/conv5_block1_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_1_bn/ReadVariableOp\n",
      "resnet50/conv5_block1_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_1_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block1_1_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block1_1_relu/Relu\n",
      "resnet50/conv5_block1_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block1_2_conv/Conv2D\n",
      "resnet50/conv5_block1_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block1_2_conv/BiasAdd\n",
      "resnet50/conv5_block1_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_2_bn/ReadVariableOp\n",
      "resnet50/conv5_block1_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_2_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block1_2_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block1_2_relu/Relu\n",
      "resnet50/conv5_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block1_3_conv/Conv2D\n",
      "resnet50/conv5_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block1_3_conv/BiasAdd\n",
      "resnet50/conv5_block1_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_3_bn/ReadVariableOp\n",
      "resnet50/conv5_block1_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_3_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block1_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block1_3_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block1_add/add\n",
      "resnet50/conv5_block1_out/Relu\n",
      "resnet50/conv5_block2_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block2_1_conv/Conv2D\n",
      "resnet50/conv5_block2_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block2_1_conv/BiasAdd\n",
      "resnet50/conv5_block2_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_1_bn/ReadVariableOp\n",
      "resnet50/conv5_block2_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block2_1_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block2_1_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block2_1_relu/Relu\n",
      "resnet50/conv5_block2_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block2_2_conv/Conv2D\n",
      "resnet50/conv5_block2_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block2_2_conv/BiasAdd\n",
      "resnet50/conv5_block2_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_2_bn/ReadVariableOp\n",
      "resnet50/conv5_block2_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block2_2_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block2_2_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block2_2_relu/Relu\n",
      "resnet50/conv5_block2_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block2_3_conv/Conv2D\n",
      "resnet50/conv5_block2_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block2_3_conv/BiasAdd\n",
      "resnet50/conv5_block2_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_3_bn/ReadVariableOp\n",
      "resnet50/conv5_block2_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block2_3_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block2_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block2_3_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block2_add/add\n",
      "resnet50/conv5_block2_out/Relu\n",
      "resnet50/conv5_block3_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_1_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block3_1_conv/Conv2D\n",
      "resnet50/conv5_block3_1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_1_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block3_1_conv/BiasAdd\n",
      "resnet50/conv5_block3_1_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_1_bn/ReadVariableOp\n",
      "resnet50/conv5_block3_1_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block3_1_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block3_1_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block3_1_relu/Relu\n",
      "resnet50/conv5_block3_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_2_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block3_2_conv/Conv2D\n",
      "resnet50/conv5_block3_2_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_2_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block3_2_conv/BiasAdd\n",
      "resnet50/conv5_block3_2_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_2_bn/ReadVariableOp\n",
      "resnet50/conv5_block3_2_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block3_2_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block3_2_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block3_2_relu/Relu\n",
      "resnet50/conv5_block3_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_3_conv/Conv2D/ReadVariableOp\n",
      "resnet50/conv5_block3_3_conv/Conv2D\n",
      "resnet50/conv5_block3_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet50/conv5_block3_3_conv/BiasAdd\n",
      "resnet50/conv5_block3_3_bn/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_3_bn/ReadVariableOp\n",
      "resnet50/conv5_block3_3_bn/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block3_3_bn/ReadVariableOp_1\n",
      "resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet50/conv5_block3_3_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet50/conv5_block3_3_bn/FusedBatchNormV3\n",
      "resnet50/conv5_block3_add/add\n",
      "resnet50/conv5_block3_out/Relu\n",
      "resnet50/avg_pool/Mean/reduction_indices\n",
      "resnet50/avg_pool/Mean\n",
      "resnet50/probs/MatMul/ReadVariableOp/resource\n",
      "resnet50/probs/MatMul/ReadVariableOp\n",
      "resnet50/probs/MatMul\n",
      "resnet50/probs/BiasAdd/ReadVariableOp/resource\n",
      "resnet50/probs/BiasAdd/ReadVariableOp\n",
      "resnet50/probs/BiasAdd\n",
      "resnet50/probs/Softmax\n",
      "Identity\n",
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(?, 224, 224, 3) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(?, 1000) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "frozen_func.graph.as_graph_def()\n",
    "\n",
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Frozen Graph as Protobuf\n",
    "Finally, we can save to hard drive, and now the frozen graph will be stored as `./frozen_models/<MODEL_NAME>_frozen_graph.pb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./frozen_models/resnet50_frozen_graph.pb'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=\"./frozen_models\",\n",
    "                  name=\"{}_frozen_graph.pb\".format(MODEL_NAME),\n",
    "                  as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming MIGraphX has already been built and installed on your system, the driver can be used to verify that the frozen graph has been correctly exported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ./frozen_models/resnet50_frozen_graph.pb\n",
      "@0 = @literal{ ... } -> float_type, {1000}, {1}\n",
      "@1 = @literal{ ... } -> float_type, {2048, 1000}, {1000, 1}\n",
      "@2 = @literal{1, 2} -> int32_type, {2}, {1}\n",
      "@3 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@4 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@5 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@6 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@7 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@8 = @literal{ ... } -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@9 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@10 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@11 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@12 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@13 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@14 = @literal{ ... } -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@15 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@16 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@17 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@18 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@19 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@20 = @literal{ ... } -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@21 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@22 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@23 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@24 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@25 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@26 = @literal{ ... } -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@27 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@28 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@29 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@30 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@31 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@32 = @literal{ ... } -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@33 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@34 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@35 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@36 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@37 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@38 = @literal{ ... } -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@39 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@40 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@41 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@42 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@43 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@44 = @literal{ ... } -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@45 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@46 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@47 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@48 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@49 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@50 = @literal{ ... } -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@51 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@52 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@53 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@54 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@55 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@56 = @literal{ ... } -> float_type, {1, 1, 1024, 512}, {524288, 524288, 512, 1}\n",
      "@57 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@58 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@59 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@60 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@61 = @literal{ ... } -> float_type, {2048}, {1}\n",
      "@62 = @literal{ ... } -> float_type, {1, 1, 1024, 2048}, {2097152, 2097152, 2048, 1}\n",
      "@63 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@64 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@65 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@66 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@67 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@68 = @literal{ ... } -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@69 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@70 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@71 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@72 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@73 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@74 = @literal{ ... } -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@75 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@76 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@77 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@78 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@79 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@80 = @literal{ ... } -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@81 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@82 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@83 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@84 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@85 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@86 = @literal{ ... } -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@87 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@88 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@89 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@90 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@91 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@92 = @literal{ ... } -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@93 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@94 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@95 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@96 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@97 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@98 = @literal{ ... } -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@99 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@100 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@101 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@102 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@103 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@104 = @literal{ ... } -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@105 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@106 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@107 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@108 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@109 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@110 = @literal{ ... } -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@111 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@112 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@113 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@114 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@115 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@116 = @literal{ ... } -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@117 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@118 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@119 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@120 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@121 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@122 = @literal{ ... } -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@123 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@124 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@125 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@126 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@127 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@128 = @literal{ ... } -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@129 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@130 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@131 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@132 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@133 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@134 = @literal{ ... } -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@135 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@136 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@137 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@138 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@139 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@140 = @literal{ ... } -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@141 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@142 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@143 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@144 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@145 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@146 = @literal{ ... } -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@147 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@148 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@149 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@150 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@151 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@152 = @literal{ ... } -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@153 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@154 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@155 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@156 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@157 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@158 = @literal{ ... } -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@159 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@160 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@161 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@162 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@163 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@164 = @literal{ ... } -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@165 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@166 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@167 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@168 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@169 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@170 = @literal{ ... } -> float_type, {1, 1, 512, 256}, {131072, 131072, 256, 1}\n",
      "@171 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@172 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@173 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@174 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@175 = @literal{ ... } -> float_type, {1024}, {1}\n",
      "@176 = @literal{ ... } -> float_type, {1, 1, 512, 1024}, {524288, 524288, 1024, 1}\n",
      "@177 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@178 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@179 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@180 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@181 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@182 = @literal{ ... } -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@183 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@184 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@185 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@186 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@187 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@188 = @literal{ ... } -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@189 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@190 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@191 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@192 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@193 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@194 = @literal{ ... } -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@195 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@196 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@197 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@198 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@199 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@200 = @literal{ ... } -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@201 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@202 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@203 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@204 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@205 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@206 = @literal{ ... } -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@207 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@208 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@209 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@210 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@211 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@212 = @literal{ ... } -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@213 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@214 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@215 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@216 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@217 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@218 = @literal{ ... } -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@219 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@220 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@221 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@222 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@223 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@224 = @literal{ ... } -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@225 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@226 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@227 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@228 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@229 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@230 = @literal{ ... } -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@231 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@232 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@233 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@234 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@235 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@236 = @literal{ ... } -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@237 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@238 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@239 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@240 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@241 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@242 = @literal{ ... } -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@243 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@244 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@245 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@246 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@247 = @literal{ ... } -> float_type, {128}, {1}\n",
      "@248 = @literal{ ... } -> float_type, {1, 1, 256, 128}, {32768, 32768, 128, 1}\n",
      "@249 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@250 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@251 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@252 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@253 = @literal{ ... } -> float_type, {512}, {1}\n",
      "@254 = @literal{ ... } -> float_type, {1, 1, 256, 512}, {131072, 131072, 512, 1}\n",
      "@255 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@256 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@257 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@258 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@259 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@260 = @literal{ ... } -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@261 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@262 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@263 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@264 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@265 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@266 = @literal{ ... } -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@267 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@268 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@269 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@270 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@271 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@272 = @literal{ ... } -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@273 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@274 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@275 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@276 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@277 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@278 = @literal{ ... } -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@279 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@280 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@281 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@282 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@283 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@284 = @literal{ ... } -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@285 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@286 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@287 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@288 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@289 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@290 = @literal{ ... } -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@291 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@292 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@293 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@294 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@295 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@296 = @literal{ ... } -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@297 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@298 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@299 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@300 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@301 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@302 = @literal{ ... } -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@303 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@304 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@305 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@306 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@307 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@308 = @literal{ ... } -> float_type, {1, 1, 64, 64}, {4096, 4096, 64, 1}\n",
      "@309 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@310 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@311 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@312 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@313 = @literal{ ... } -> float_type, {256}, {1}\n",
      "@314 = @literal{ ... } -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@315 = @literal{0, 0, 1, 1, 1, 1, 0, 0} -> int32_type, {4, 2}, {2, 1}\n",
      "@316 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@317 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@318 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@319 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@320 = @literal{ ... } -> float_type, {64}, {1}\n",
      "@321 = @literal{ ... } -> float_type, {7, 7, 3, 64}, {1344, 192, 64, 1}\n",
      "@322 = @literal{0, 0, 3, 3, 3, 3, 0, 0} -> int32_type, {4, 2}, {2, 1}\n",
      "x = @param:x -> float_type, {1, 3, 224, 224}, {150528, 50176, 224, 1}\n",
      "@323 = transpose[dims={0, 2, 3, 1}](x) -> float_type, {1, 224, 224, 3}, {150528, 224, 1, 50176}\n",
      "@324 = transpose[dims={0, 3, 1, 2}](@323) -> float_type, {1, 3, 224, 224}, {150528, 50176, 224, 1}\n",
      "@325 = pad[mode=0,pads={0, 0, 3, 3, 0, 0, 3, 3},value=0](@324) -> float_type, {1, 3, 230, 230}, {158700, 52900, 230, 1}\n",
      "@326 = transpose[dims={0, 2, 3, 1}](@325) -> float_type, {1, 230, 230, 3}, {158700, 230, 1, 52900}\n",
      "@327 = transpose[dims={0, 2, 3, 1}](@321) -> float_type, {7, 3, 64, 7}, {1344, 64, 1, 192}\n",
      "@328 = transpose[dims={0, 3, 1, 2}](@327) -> float_type, {7, 7, 3, 64}, {1344, 192, 64, 1}\n",
      "@329 = identity(@328) -> float_type, {7, 7, 3, 64}, {1344, 192, 64, 1}\n",
      "@330 = transpose[dims={0, 2, 3, 1}](@329) -> float_type, {7, 3, 64, 7}, {1344, 64, 1, 192}\n",
      "@331 = transpose[dims={0, 3, 1, 2}](@326) -> float_type, {1, 3, 230, 230}, {158700, 52900, 230, 1}\n",
      "@332 = transpose[dims={0, 3, 1, 2}](@330) -> float_type, {7, 7, 3, 64}, {1344, 192, 64, 1}\n",
      "@333 = transpose[dims={3, 2, 0, 1}](@332) -> float_type, {64, 3, 7, 7}, {1, 64, 1344, 192}\n",
      "@334 = transpose[dims={3, 2, 0, 1}](@332) -> float_type, {64, 3, 7, 7}, {1, 64, 1344, 192}\n",
      "@335 = convolution[padding={0, 0},stride={2, 2},dilation={1, 1},group=1,padding_mode=2](@331,@334) -> float_type, {1, 64, 112, 112}, {802816, 12544, 112, 1}\n",
      "@336 = transpose[dims={0, 2, 3, 1}](@335) -> float_type, {1, 112, 112, 64}, {802816, 112, 1, 12544}\n",
      "@337 = identity(@320) -> float_type, {64}, {1}\n",
      "@338 = transpose[dims={0, 3, 1, 2}](@336) -> float_type, {1, 64, 112, 112}, {802816, 12544, 112, 1}\n",
      "@339 = broadcast[axis=1,dims={1, 64, 112, 112}](@337) -> float_type, {1, 64, 112, 112}, {0, 1, 0, 0}\n",
      "@340 = add(@338,@339) -> float_type, {1, 64, 112, 112}, {802816, 12544, 112, 1}\n",
      "@341 = transpose[dims={0, 2, 3, 1}](@340) -> float_type, {1, 112, 112, 64}, {802816, 112, 1, 12544}\n",
      "@342 = identity(@319) -> float_type, {64}, {1}\n",
      "@343 = identity(@318) -> float_type, {64}, {1}\n",
      "@344 = identity(@317) -> float_type, {64}, {1}\n",
      "@345 = identity(@316) -> float_type, {64}, {1}\n",
      "@346 = unknown:FusedBatchNormV3(@341,@342,@343,@344,@345) -> float_type, {1, 112, 112, 64}, {802816, 112, 1, 12544}\n",
      "@347 = transpose[dims={0, 3, 1, 2}](@346) -> float_type, {1, 64, 112, 112}, {802816, 12544, 112, 1}\n",
      "@348 = relu(@347) -> float_type, {1, 64, 112, 112}, {802816, 12544, 112, 1}\n",
      "@349 = transpose[dims={0, 2, 3, 1}](@348) -> float_type, {1, 112, 112, 64}, {802816, 112, 1, 12544}\n",
      "@350 = transpose[dims={0, 3, 1, 2}](@349) -> float_type, {1, 64, 112, 112}, {802816, 12544, 112, 1}\n",
      "@351 = pad[mode=0,pads={0, 0, 1, 1, 0, 0, 1, 1},value=0](@350) -> float_type, {1, 64, 114, 114}, {831744, 12996, 114, 1}\n",
      "@352 = transpose[dims={0, 2, 3, 1}](@351) -> float_type, {1, 114, 114, 64}, {831744, 114, 1, 12996}\n",
      "@353 = transpose[dims={0, 3, 1, 2}](@352) -> float_type, {1, 64, 114, 114}, {831744, 12996, 114, 1}\n",
      "@354 = pooling[mode=max,padding={0, 0},stride={2, 2},lengths={3, 3},ceil_mode=0](@353) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@355 = transpose[dims={0, 2, 3, 1}](@354) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@356 = transpose[dims={0, 2, 3, 1}](@314) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@357 = transpose[dims={0, 3, 1, 2}](@356) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@358 = identity(@357) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@359 = transpose[dims={0, 2, 3, 1}](@358) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@360 = transpose[dims={0, 3, 1, 2}](@355) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@361 = transpose[dims={0, 3, 1, 2}](@359) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@362 = transpose[dims={3, 2, 0, 1}](@361) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@363 = transpose[dims={3, 2, 0, 1}](@361) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@364 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@360,@363) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@365 = transpose[dims={0, 2, 3, 1}](@364) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@366 = identity(@313) -> float_type, {256}, {1}\n",
      "@367 = transpose[dims={0, 3, 1, 2}](@365) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@368 = broadcast[axis=1,dims={1, 256, 56, 56}](@366) -> float_type, {1, 256, 56, 56}, {0, 1, 0, 0}\n",
      "@369 = add(@367,@368) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@370 = transpose[dims={0, 2, 3, 1}](@369) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@371 = identity(@312) -> float_type, {256}, {1}\n",
      "@372 = identity(@311) -> float_type, {256}, {1}\n",
      "@373 = identity(@310) -> float_type, {256}, {1}\n",
      "@374 = identity(@309) -> float_type, {256}, {1}\n",
      "@375 = unknown:FusedBatchNormV3(@370,@371,@372,@373,@374) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@376 = transpose[dims={0, 2, 3, 1}](@308) -> float_type, {1, 64, 64, 1}, {4096, 64, 1, 4096}\n",
      "@377 = transpose[dims={0, 3, 1, 2}](@376) -> float_type, {1, 1, 64, 64}, {4096, 4096, 64, 1}\n",
      "@378 = identity(@377) -> float_type, {1, 1, 64, 64}, {4096, 4096, 64, 1}\n",
      "@379 = transpose[dims={0, 2, 3, 1}](@378) -> float_type, {1, 64, 64, 1}, {4096, 64, 1, 4096}\n",
      "@380 = transpose[dims={0, 3, 1, 2}](@355) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@381 = transpose[dims={0, 3, 1, 2}](@379) -> float_type, {1, 1, 64, 64}, {4096, 4096, 64, 1}\n",
      "@382 = transpose[dims={3, 2, 0, 1}](@381) -> float_type, {64, 64, 1, 1}, {1, 64, 4096, 4096}\n",
      "@383 = transpose[dims={3, 2, 0, 1}](@381) -> float_type, {64, 64, 1, 1}, {1, 64, 4096, 4096}\n",
      "@384 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@380,@383) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@385 = transpose[dims={0, 2, 3, 1}](@384) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@386 = identity(@307) -> float_type, {64}, {1}\n",
      "@387 = transpose[dims={0, 3, 1, 2}](@385) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@388 = broadcast[axis=1,dims={1, 64, 56, 56}](@386) -> float_type, {1, 64, 56, 56}, {0, 1, 0, 0}\n",
      "@389 = add(@387,@388) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@390 = transpose[dims={0, 2, 3, 1}](@389) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@391 = identity(@306) -> float_type, {64}, {1}\n",
      "@392 = identity(@305) -> float_type, {64}, {1}\n",
      "@393 = identity(@304) -> float_type, {64}, {1}\n",
      "@394 = identity(@303) -> float_type, {64}, {1}\n",
      "@395 = unknown:FusedBatchNormV3(@390,@391,@392,@393,@394) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@396 = transpose[dims={0, 3, 1, 2}](@395) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@397 = relu(@396) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@398 = transpose[dims={0, 2, 3, 1}](@397) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@399 = transpose[dims={0, 2, 3, 1}](@302) -> float_type, {3, 64, 64, 3}, {12288, 64, 1, 4096}\n",
      "@400 = transpose[dims={0, 3, 1, 2}](@399) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@401 = identity(@400) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@402 = transpose[dims={0, 2, 3, 1}](@401) -> float_type, {3, 64, 64, 3}, {12288, 64, 1, 4096}\n",
      "@403 = transpose[dims={0, 3, 1, 2}](@398) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@404 = transpose[dims={0, 3, 1, 2}](@402) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@405 = transpose[dims={3, 2, 0, 1}](@404) -> float_type, {64, 64, 3, 3}, {1, 64, 12288, 4096}\n",
      "@406 = transpose[dims={3, 2, 0, 1}](@404) -> float_type, {64, 64, 3, 3}, {1, 64, 12288, 4096}\n",
      "@407 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@403,@406) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@408 = transpose[dims={0, 2, 3, 1}](@407) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@409 = identity(@301) -> float_type, {64}, {1}\n",
      "@410 = transpose[dims={0, 3, 1, 2}](@408) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@411 = broadcast[axis=1,dims={1, 64, 56, 56}](@409) -> float_type, {1, 64, 56, 56}, {0, 1, 0, 0}\n",
      "@412 = add(@410,@411) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@413 = transpose[dims={0, 2, 3, 1}](@412) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@414 = identity(@300) -> float_type, {64}, {1}\n",
      "@415 = identity(@299) -> float_type, {64}, {1}\n",
      "@416 = identity(@298) -> float_type, {64}, {1}\n",
      "@417 = identity(@297) -> float_type, {64}, {1}\n",
      "@418 = unknown:FusedBatchNormV3(@413,@414,@415,@416,@417) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@419 = transpose[dims={0, 3, 1, 2}](@418) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@420 = relu(@419) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@421 = transpose[dims={0, 2, 3, 1}](@420) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@422 = transpose[dims={0, 2, 3, 1}](@296) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@423 = transpose[dims={0, 3, 1, 2}](@422) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@424 = identity(@423) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@425 = transpose[dims={0, 2, 3, 1}](@424) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@426 = transpose[dims={0, 3, 1, 2}](@421) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@427 = transpose[dims={0, 3, 1, 2}](@425) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@428 = transpose[dims={3, 2, 0, 1}](@427) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@429 = transpose[dims={3, 2, 0, 1}](@427) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@430 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@426,@429) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@431 = transpose[dims={0, 2, 3, 1}](@430) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@432 = identity(@295) -> float_type, {256}, {1}\n",
      "@433 = transpose[dims={0, 3, 1, 2}](@431) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@434 = broadcast[axis=1,dims={1, 256, 56, 56}](@432) -> float_type, {1, 256, 56, 56}, {0, 1, 0, 0}\n",
      "@435 = add(@433,@434) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@436 = transpose[dims={0, 2, 3, 1}](@435) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@437 = identity(@294) -> float_type, {256}, {1}\n",
      "@438 = identity(@293) -> float_type, {256}, {1}\n",
      "@439 = identity(@292) -> float_type, {256}, {1}\n",
      "@440 = identity(@291) -> float_type, {256}, {1}\n",
      "@441 = unknown:FusedBatchNormV3(@436,@437,@438,@439,@440) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@442 = unknown:AddV2(@375,@441) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@443 = transpose[dims={0, 3, 1, 2}](@442) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@444 = relu(@443) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@445 = transpose[dims={0, 2, 3, 1}](@444) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@446 = transpose[dims={0, 2, 3, 1}](@290) -> float_type, {1, 256, 64, 1}, {16384, 64, 1, 16384}\n",
      "@447 = transpose[dims={0, 3, 1, 2}](@446) -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@448 = identity(@447) -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@449 = transpose[dims={0, 2, 3, 1}](@448) -> float_type, {1, 256, 64, 1}, {16384, 64, 1, 16384}\n",
      "@450 = transpose[dims={0, 3, 1, 2}](@445) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@451 = transpose[dims={0, 3, 1, 2}](@449) -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@452 = transpose[dims={3, 2, 0, 1}](@451) -> float_type, {64, 256, 1, 1}, {1, 64, 16384, 16384}\n",
      "@453 = transpose[dims={3, 2, 0, 1}](@451) -> float_type, {64, 256, 1, 1}, {1, 64, 16384, 16384}\n",
      "@454 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@450,@453) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@455 = transpose[dims={0, 2, 3, 1}](@454) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@456 = identity(@289) -> float_type, {64}, {1}\n",
      "@457 = transpose[dims={0, 3, 1, 2}](@455) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@458 = broadcast[axis=1,dims={1, 64, 56, 56}](@456) -> float_type, {1, 64, 56, 56}, {0, 1, 0, 0}\n",
      "@459 = add(@457,@458) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@460 = transpose[dims={0, 2, 3, 1}](@459) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@461 = identity(@288) -> float_type, {64}, {1}\n",
      "@462 = identity(@287) -> float_type, {64}, {1}\n",
      "@463 = identity(@286) -> float_type, {64}, {1}\n",
      "@464 = identity(@285) -> float_type, {64}, {1}\n",
      "@465 = unknown:FusedBatchNormV3(@460,@461,@462,@463,@464) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@466 = transpose[dims={0, 3, 1, 2}](@465) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@467 = relu(@466) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@468 = transpose[dims={0, 2, 3, 1}](@467) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@469 = transpose[dims={0, 2, 3, 1}](@284) -> float_type, {3, 64, 64, 3}, {12288, 64, 1, 4096}\n",
      "@470 = transpose[dims={0, 3, 1, 2}](@469) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@471 = identity(@470) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@472 = transpose[dims={0, 2, 3, 1}](@471) -> float_type, {3, 64, 64, 3}, {12288, 64, 1, 4096}\n",
      "@473 = transpose[dims={0, 3, 1, 2}](@468) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@474 = transpose[dims={0, 3, 1, 2}](@472) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@475 = transpose[dims={3, 2, 0, 1}](@474) -> float_type, {64, 64, 3, 3}, {1, 64, 12288, 4096}\n",
      "@476 = transpose[dims={3, 2, 0, 1}](@474) -> float_type, {64, 64, 3, 3}, {1, 64, 12288, 4096}\n",
      "@477 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@473,@476) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@478 = transpose[dims={0, 2, 3, 1}](@477) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@479 = identity(@283) -> float_type, {64}, {1}\n",
      "@480 = transpose[dims={0, 3, 1, 2}](@478) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@481 = broadcast[axis=1,dims={1, 64, 56, 56}](@479) -> float_type, {1, 64, 56, 56}, {0, 1, 0, 0}\n",
      "@482 = add(@480,@481) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@483 = transpose[dims={0, 2, 3, 1}](@482) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@484 = identity(@282) -> float_type, {64}, {1}\n",
      "@485 = identity(@281) -> float_type, {64}, {1}\n",
      "@486 = identity(@280) -> float_type, {64}, {1}\n",
      "@487 = identity(@279) -> float_type, {64}, {1}\n",
      "@488 = unknown:FusedBatchNormV3(@483,@484,@485,@486,@487) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@489 = transpose[dims={0, 3, 1, 2}](@488) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@490 = relu(@489) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@491 = transpose[dims={0, 2, 3, 1}](@490) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@492 = transpose[dims={0, 2, 3, 1}](@278) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@493 = transpose[dims={0, 3, 1, 2}](@492) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@494 = identity(@493) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@495 = transpose[dims={0, 2, 3, 1}](@494) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@496 = transpose[dims={0, 3, 1, 2}](@491) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@497 = transpose[dims={0, 3, 1, 2}](@495) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@498 = transpose[dims={3, 2, 0, 1}](@497) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@499 = transpose[dims={3, 2, 0, 1}](@497) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@500 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@496,@499) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@501 = transpose[dims={0, 2, 3, 1}](@500) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@502 = identity(@277) -> float_type, {256}, {1}\n",
      "@503 = transpose[dims={0, 3, 1, 2}](@501) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@504 = broadcast[axis=1,dims={1, 256, 56, 56}](@502) -> float_type, {1, 256, 56, 56}, {0, 1, 0, 0}\n",
      "@505 = add(@503,@504) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@506 = transpose[dims={0, 2, 3, 1}](@505) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@507 = identity(@276) -> float_type, {256}, {1}\n",
      "@508 = identity(@275) -> float_type, {256}, {1}\n",
      "@509 = identity(@274) -> float_type, {256}, {1}\n",
      "@510 = identity(@273) -> float_type, {256}, {1}\n",
      "@511 = unknown:FusedBatchNormV3(@506,@507,@508,@509,@510) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@512 = unknown:AddV2(@445,@511) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@513 = transpose[dims={0, 3, 1, 2}](@512) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@514 = relu(@513) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@515 = transpose[dims={0, 2, 3, 1}](@514) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@516 = transpose[dims={0, 2, 3, 1}](@272) -> float_type, {1, 256, 64, 1}, {16384, 64, 1, 16384}\n",
      "@517 = transpose[dims={0, 3, 1, 2}](@516) -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@518 = identity(@517) -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@519 = transpose[dims={0, 2, 3, 1}](@518) -> float_type, {1, 256, 64, 1}, {16384, 64, 1, 16384}\n",
      "@520 = transpose[dims={0, 3, 1, 2}](@515) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@521 = transpose[dims={0, 3, 1, 2}](@519) -> float_type, {1, 1, 256, 64}, {16384, 16384, 64, 1}\n",
      "@522 = transpose[dims={3, 2, 0, 1}](@521) -> float_type, {64, 256, 1, 1}, {1, 64, 16384, 16384}\n",
      "@523 = transpose[dims={3, 2, 0, 1}](@521) -> float_type, {64, 256, 1, 1}, {1, 64, 16384, 16384}\n",
      "@524 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@520,@523) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@525 = transpose[dims={0, 2, 3, 1}](@524) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@526 = identity(@271) -> float_type, {64}, {1}\n",
      "@527 = transpose[dims={0, 3, 1, 2}](@525) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@528 = broadcast[axis=1,dims={1, 64, 56, 56}](@526) -> float_type, {1, 64, 56, 56}, {0, 1, 0, 0}\n",
      "@529 = add(@527,@528) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@530 = transpose[dims={0, 2, 3, 1}](@529) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@531 = identity(@270) -> float_type, {64}, {1}\n",
      "@532 = identity(@269) -> float_type, {64}, {1}\n",
      "@533 = identity(@268) -> float_type, {64}, {1}\n",
      "@534 = identity(@267) -> float_type, {64}, {1}\n",
      "@535 = unknown:FusedBatchNormV3(@530,@531,@532,@533,@534) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@536 = transpose[dims={0, 3, 1, 2}](@535) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@537 = relu(@536) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@538 = transpose[dims={0, 2, 3, 1}](@537) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@539 = transpose[dims={0, 2, 3, 1}](@266) -> float_type, {3, 64, 64, 3}, {12288, 64, 1, 4096}\n",
      "@540 = transpose[dims={0, 3, 1, 2}](@539) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@541 = identity(@540) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@542 = transpose[dims={0, 2, 3, 1}](@541) -> float_type, {3, 64, 64, 3}, {12288, 64, 1, 4096}\n",
      "@543 = transpose[dims={0, 3, 1, 2}](@538) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@544 = transpose[dims={0, 3, 1, 2}](@542) -> float_type, {3, 3, 64, 64}, {12288, 4096, 64, 1}\n",
      "@545 = transpose[dims={3, 2, 0, 1}](@544) -> float_type, {64, 64, 3, 3}, {1, 64, 12288, 4096}\n",
      "@546 = transpose[dims={3, 2, 0, 1}](@544) -> float_type, {64, 64, 3, 3}, {1, 64, 12288, 4096}\n",
      "@547 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@543,@546) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@548 = transpose[dims={0, 2, 3, 1}](@547) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@549 = identity(@265) -> float_type, {64}, {1}\n",
      "@550 = transpose[dims={0, 3, 1, 2}](@548) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@551 = broadcast[axis=1,dims={1, 64, 56, 56}](@549) -> float_type, {1, 64, 56, 56}, {0, 1, 0, 0}\n",
      "@552 = add(@550,@551) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@553 = transpose[dims={0, 2, 3, 1}](@552) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@554 = identity(@264) -> float_type, {64}, {1}\n",
      "@555 = identity(@263) -> float_type, {64}, {1}\n",
      "@556 = identity(@262) -> float_type, {64}, {1}\n",
      "@557 = identity(@261) -> float_type, {64}, {1}\n",
      "@558 = unknown:FusedBatchNormV3(@553,@554,@555,@556,@557) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@559 = transpose[dims={0, 3, 1, 2}](@558) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@560 = relu(@559) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@561 = transpose[dims={0, 2, 3, 1}](@560) -> float_type, {1, 56, 56, 64}, {200704, 56, 1, 3136}\n",
      "@562 = transpose[dims={0, 2, 3, 1}](@260) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@563 = transpose[dims={0, 3, 1, 2}](@562) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@564 = identity(@563) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@565 = transpose[dims={0, 2, 3, 1}](@564) -> float_type, {1, 64, 256, 1}, {16384, 256, 1, 16384}\n",
      "@566 = transpose[dims={0, 3, 1, 2}](@561) -> float_type, {1, 64, 56, 56}, {200704, 3136, 56, 1}\n",
      "@567 = transpose[dims={0, 3, 1, 2}](@565) -> float_type, {1, 1, 64, 256}, {16384, 16384, 256, 1}\n",
      "@568 = transpose[dims={3, 2, 0, 1}](@567) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@569 = transpose[dims={3, 2, 0, 1}](@567) -> float_type, {256, 64, 1, 1}, {1, 256, 16384, 16384}\n",
      "@570 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@566,@569) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@571 = transpose[dims={0, 2, 3, 1}](@570) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@572 = identity(@259) -> float_type, {256}, {1}\n",
      "@573 = transpose[dims={0, 3, 1, 2}](@571) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@574 = broadcast[axis=1,dims={1, 256, 56, 56}](@572) -> float_type, {1, 256, 56, 56}, {0, 1, 0, 0}\n",
      "@575 = add(@573,@574) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@576 = transpose[dims={0, 2, 3, 1}](@575) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@577 = identity(@258) -> float_type, {256}, {1}\n",
      "@578 = identity(@257) -> float_type, {256}, {1}\n",
      "@579 = identity(@256) -> float_type, {256}, {1}\n",
      "@580 = identity(@255) -> float_type, {256}, {1}\n",
      "@581 = unknown:FusedBatchNormV3(@576,@577,@578,@579,@580) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@582 = unknown:AddV2(@515,@581) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@583 = transpose[dims={0, 3, 1, 2}](@582) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@584 = relu(@583) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@585 = transpose[dims={0, 2, 3, 1}](@584) -> float_type, {1, 56, 56, 256}, {802816, 56, 1, 3136}\n",
      "@586 = transpose[dims={0, 2, 3, 1}](@254) -> float_type, {1, 256, 512, 1}, {131072, 512, 1, 131072}\n",
      "@587 = transpose[dims={0, 3, 1, 2}](@586) -> float_type, {1, 1, 256, 512}, {131072, 131072, 512, 1}\n",
      "@588 = identity(@587) -> float_type, {1, 1, 256, 512}, {131072, 131072, 512, 1}\n",
      "@589 = transpose[dims={0, 2, 3, 1}](@588) -> float_type, {1, 256, 512, 1}, {131072, 512, 1, 131072}\n",
      "@590 = transpose[dims={0, 3, 1, 2}](@585) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@591 = transpose[dims={0, 3, 1, 2}](@589) -> float_type, {1, 1, 256, 512}, {131072, 131072, 512, 1}\n",
      "@592 = transpose[dims={3, 2, 0, 1}](@591) -> float_type, {512, 256, 1, 1}, {1, 512, 131072, 131072}\n",
      "@593 = transpose[dims={3, 2, 0, 1}](@591) -> float_type, {512, 256, 1, 1}, {1, 512, 131072, 131072}\n",
      "@594 = convolution[padding={0, 0},stride={2, 2},dilation={1, 1},group=1,padding_mode=2](@590,@593) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@595 = transpose[dims={0, 2, 3, 1}](@594) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@596 = identity(@253) -> float_type, {512}, {1}\n",
      "@597 = transpose[dims={0, 3, 1, 2}](@595) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@598 = broadcast[axis=1,dims={1, 512, 28, 28}](@596) -> float_type, {1, 512, 28, 28}, {0, 1, 0, 0}\n",
      "@599 = add(@597,@598) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@600 = transpose[dims={0, 2, 3, 1}](@599) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@601 = identity(@252) -> float_type, {512}, {1}\n",
      "@602 = identity(@251) -> float_type, {512}, {1}\n",
      "@603 = identity(@250) -> float_type, {512}, {1}\n",
      "@604 = identity(@249) -> float_type, {512}, {1}\n",
      "@605 = unknown:FusedBatchNormV3(@600,@601,@602,@603,@604) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@606 = transpose[dims={0, 2, 3, 1}](@248) -> float_type, {1, 256, 128, 1}, {32768, 128, 1, 32768}\n",
      "@607 = transpose[dims={0, 3, 1, 2}](@606) -> float_type, {1, 1, 256, 128}, {32768, 32768, 128, 1}\n",
      "@608 = identity(@607) -> float_type, {1, 1, 256, 128}, {32768, 32768, 128, 1}\n",
      "@609 = transpose[dims={0, 2, 3, 1}](@608) -> float_type, {1, 256, 128, 1}, {32768, 128, 1, 32768}\n",
      "@610 = transpose[dims={0, 3, 1, 2}](@585) -> float_type, {1, 256, 56, 56}, {802816, 3136, 56, 1}\n",
      "@611 = transpose[dims={0, 3, 1, 2}](@609) -> float_type, {1, 1, 256, 128}, {32768, 32768, 128, 1}\n",
      "@612 = transpose[dims={3, 2, 0, 1}](@611) -> float_type, {128, 256, 1, 1}, {1, 128, 32768, 32768}\n",
      "@613 = transpose[dims={3, 2, 0, 1}](@611) -> float_type, {128, 256, 1, 1}, {1, 128, 32768, 32768}\n",
      "@614 = convolution[padding={0, 0},stride={2, 2},dilation={1, 1},group=1,padding_mode=2](@610,@613) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@615 = transpose[dims={0, 2, 3, 1}](@614) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@616 = identity(@247) -> float_type, {128}, {1}\n",
      "@617 = transpose[dims={0, 3, 1, 2}](@615) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@618 = broadcast[axis=1,dims={1, 128, 28, 28}](@616) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@619 = add(@617,@618) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@620 = transpose[dims={0, 2, 3, 1}](@619) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@621 = identity(@246) -> float_type, {128}, {1}\n",
      "@622 = identity(@245) -> float_type, {128}, {1}\n",
      "@623 = identity(@244) -> float_type, {128}, {1}\n",
      "@624 = identity(@243) -> float_type, {128}, {1}\n",
      "@625 = unknown:FusedBatchNormV3(@620,@621,@622,@623,@624) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@626 = transpose[dims={0, 3, 1, 2}](@625) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@627 = relu(@626) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@628 = transpose[dims={0, 2, 3, 1}](@627) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@629 = transpose[dims={0, 2, 3, 1}](@242) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@630 = transpose[dims={0, 3, 1, 2}](@629) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@631 = identity(@630) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@632 = transpose[dims={0, 2, 3, 1}](@631) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@633 = transpose[dims={0, 3, 1, 2}](@628) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@634 = transpose[dims={0, 3, 1, 2}](@632) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@635 = transpose[dims={3, 2, 0, 1}](@634) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@636 = transpose[dims={3, 2, 0, 1}](@634) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@637 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@633,@636) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@638 = transpose[dims={0, 2, 3, 1}](@637) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@639 = identity(@241) -> float_type, {128}, {1}\n",
      "@640 = transpose[dims={0, 3, 1, 2}](@638) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@641 = broadcast[axis=1,dims={1, 128, 28, 28}](@639) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@642 = add(@640,@641) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@643 = transpose[dims={0, 2, 3, 1}](@642) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@644 = identity(@240) -> float_type, {128}, {1}\n",
      "@645 = identity(@239) -> float_type, {128}, {1}\n",
      "@646 = identity(@238) -> float_type, {128}, {1}\n",
      "@647 = identity(@237) -> float_type, {128}, {1}\n",
      "@648 = unknown:FusedBatchNormV3(@643,@644,@645,@646,@647) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@649 = transpose[dims={0, 3, 1, 2}](@648) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@650 = relu(@649) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@651 = transpose[dims={0, 2, 3, 1}](@650) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@652 = transpose[dims={0, 2, 3, 1}](@236) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@653 = transpose[dims={0, 3, 1, 2}](@652) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@654 = identity(@653) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@655 = transpose[dims={0, 2, 3, 1}](@654) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@656 = transpose[dims={0, 3, 1, 2}](@651) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@657 = transpose[dims={0, 3, 1, 2}](@655) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@658 = transpose[dims={3, 2, 0, 1}](@657) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@659 = transpose[dims={3, 2, 0, 1}](@657) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@660 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@656,@659) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@661 = transpose[dims={0, 2, 3, 1}](@660) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@662 = identity(@235) -> float_type, {512}, {1}\n",
      "@663 = transpose[dims={0, 3, 1, 2}](@661) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@664 = broadcast[axis=1,dims={1, 512, 28, 28}](@662) -> float_type, {1, 512, 28, 28}, {0, 1, 0, 0}\n",
      "@665 = add(@663,@664) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@666 = transpose[dims={0, 2, 3, 1}](@665) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@667 = identity(@234) -> float_type, {512}, {1}\n",
      "@668 = identity(@233) -> float_type, {512}, {1}\n",
      "@669 = identity(@232) -> float_type, {512}, {1}\n",
      "@670 = identity(@231) -> float_type, {512}, {1}\n",
      "@671 = unknown:FusedBatchNormV3(@666,@667,@668,@669,@670) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@672 = unknown:AddV2(@605,@671) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@673 = transpose[dims={0, 3, 1, 2}](@672) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@674 = relu(@673) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@675 = transpose[dims={0, 2, 3, 1}](@674) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@676 = transpose[dims={0, 2, 3, 1}](@230) -> float_type, {1, 512, 128, 1}, {65536, 128, 1, 65536}\n",
      "@677 = transpose[dims={0, 3, 1, 2}](@676) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@678 = identity(@677) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@679 = transpose[dims={0, 2, 3, 1}](@678) -> float_type, {1, 512, 128, 1}, {65536, 128, 1, 65536}\n",
      "@680 = transpose[dims={0, 3, 1, 2}](@675) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@681 = transpose[dims={0, 3, 1, 2}](@679) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@682 = transpose[dims={3, 2, 0, 1}](@681) -> float_type, {128, 512, 1, 1}, {1, 128, 65536, 65536}\n",
      "@683 = transpose[dims={3, 2, 0, 1}](@681) -> float_type, {128, 512, 1, 1}, {1, 128, 65536, 65536}\n",
      "@684 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@680,@683) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@685 = transpose[dims={0, 2, 3, 1}](@684) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@686 = identity(@229) -> float_type, {128}, {1}\n",
      "@687 = transpose[dims={0, 3, 1, 2}](@685) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@688 = broadcast[axis=1,dims={1, 128, 28, 28}](@686) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@689 = add(@687,@688) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@690 = transpose[dims={0, 2, 3, 1}](@689) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@691 = identity(@228) -> float_type, {128}, {1}\n",
      "@692 = identity(@227) -> float_type, {128}, {1}\n",
      "@693 = identity(@226) -> float_type, {128}, {1}\n",
      "@694 = identity(@225) -> float_type, {128}, {1}\n",
      "@695 = unknown:FusedBatchNormV3(@690,@691,@692,@693,@694) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@696 = transpose[dims={0, 3, 1, 2}](@695) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@697 = relu(@696) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@698 = transpose[dims={0, 2, 3, 1}](@697) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@699 = transpose[dims={0, 2, 3, 1}](@224) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@700 = transpose[dims={0, 3, 1, 2}](@699) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@701 = identity(@700) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@702 = transpose[dims={0, 2, 3, 1}](@701) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@703 = transpose[dims={0, 3, 1, 2}](@698) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@704 = transpose[dims={0, 3, 1, 2}](@702) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@705 = transpose[dims={3, 2, 0, 1}](@704) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@706 = transpose[dims={3, 2, 0, 1}](@704) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@707 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@703,@706) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@708 = transpose[dims={0, 2, 3, 1}](@707) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@709 = identity(@223) -> float_type, {128}, {1}\n",
      "@710 = transpose[dims={0, 3, 1, 2}](@708) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@711 = broadcast[axis=1,dims={1, 128, 28, 28}](@709) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@712 = add(@710,@711) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@713 = transpose[dims={0, 2, 3, 1}](@712) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@714 = identity(@222) -> float_type, {128}, {1}\n",
      "@715 = identity(@221) -> float_type, {128}, {1}\n",
      "@716 = identity(@220) -> float_type, {128}, {1}\n",
      "@717 = identity(@219) -> float_type, {128}, {1}\n",
      "@718 = unknown:FusedBatchNormV3(@713,@714,@715,@716,@717) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@719 = transpose[dims={0, 3, 1, 2}](@718) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@720 = relu(@719) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@721 = transpose[dims={0, 2, 3, 1}](@720) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@722 = transpose[dims={0, 2, 3, 1}](@218) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@723 = transpose[dims={0, 3, 1, 2}](@722) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@724 = identity(@723) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@725 = transpose[dims={0, 2, 3, 1}](@724) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@726 = transpose[dims={0, 3, 1, 2}](@721) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@727 = transpose[dims={0, 3, 1, 2}](@725) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@728 = transpose[dims={3, 2, 0, 1}](@727) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@729 = transpose[dims={3, 2, 0, 1}](@727) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@730 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@726,@729) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@731 = transpose[dims={0, 2, 3, 1}](@730) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@732 = identity(@217) -> float_type, {512}, {1}\n",
      "@733 = transpose[dims={0, 3, 1, 2}](@731) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@734 = broadcast[axis=1,dims={1, 512, 28, 28}](@732) -> float_type, {1, 512, 28, 28}, {0, 1, 0, 0}\n",
      "@735 = add(@733,@734) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@736 = transpose[dims={0, 2, 3, 1}](@735) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@737 = identity(@216) -> float_type, {512}, {1}\n",
      "@738 = identity(@215) -> float_type, {512}, {1}\n",
      "@739 = identity(@214) -> float_type, {512}, {1}\n",
      "@740 = identity(@213) -> float_type, {512}, {1}\n",
      "@741 = unknown:FusedBatchNormV3(@736,@737,@738,@739,@740) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@742 = unknown:AddV2(@675,@741) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@743 = transpose[dims={0, 3, 1, 2}](@742) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@744 = relu(@743) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@745 = transpose[dims={0, 2, 3, 1}](@744) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@746 = transpose[dims={0, 2, 3, 1}](@212) -> float_type, {1, 512, 128, 1}, {65536, 128, 1, 65536}\n",
      "@747 = transpose[dims={0, 3, 1, 2}](@746) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@748 = identity(@747) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@749 = transpose[dims={0, 2, 3, 1}](@748) -> float_type, {1, 512, 128, 1}, {65536, 128, 1, 65536}\n",
      "@750 = transpose[dims={0, 3, 1, 2}](@745) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@751 = transpose[dims={0, 3, 1, 2}](@749) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@752 = transpose[dims={3, 2, 0, 1}](@751) -> float_type, {128, 512, 1, 1}, {1, 128, 65536, 65536}\n",
      "@753 = transpose[dims={3, 2, 0, 1}](@751) -> float_type, {128, 512, 1, 1}, {1, 128, 65536, 65536}\n",
      "@754 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@750,@753) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@755 = transpose[dims={0, 2, 3, 1}](@754) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@756 = identity(@211) -> float_type, {128}, {1}\n",
      "@757 = transpose[dims={0, 3, 1, 2}](@755) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@758 = broadcast[axis=1,dims={1, 128, 28, 28}](@756) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@759 = add(@757,@758) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@760 = transpose[dims={0, 2, 3, 1}](@759) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@761 = identity(@210) -> float_type, {128}, {1}\n",
      "@762 = identity(@209) -> float_type, {128}, {1}\n",
      "@763 = identity(@208) -> float_type, {128}, {1}\n",
      "@764 = identity(@207) -> float_type, {128}, {1}\n",
      "@765 = unknown:FusedBatchNormV3(@760,@761,@762,@763,@764) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@766 = transpose[dims={0, 3, 1, 2}](@765) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@767 = relu(@766) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@768 = transpose[dims={0, 2, 3, 1}](@767) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@769 = transpose[dims={0, 2, 3, 1}](@206) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@770 = transpose[dims={0, 3, 1, 2}](@769) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@771 = identity(@770) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@772 = transpose[dims={0, 2, 3, 1}](@771) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@773 = transpose[dims={0, 3, 1, 2}](@768) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@774 = transpose[dims={0, 3, 1, 2}](@772) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@775 = transpose[dims={3, 2, 0, 1}](@774) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@776 = transpose[dims={3, 2, 0, 1}](@774) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@777 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@773,@776) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@778 = transpose[dims={0, 2, 3, 1}](@777) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@779 = identity(@205) -> float_type, {128}, {1}\n",
      "@780 = transpose[dims={0, 3, 1, 2}](@778) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@781 = broadcast[axis=1,dims={1, 128, 28, 28}](@779) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@782 = add(@780,@781) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@783 = transpose[dims={0, 2, 3, 1}](@782) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@784 = identity(@204) -> float_type, {128}, {1}\n",
      "@785 = identity(@203) -> float_type, {128}, {1}\n",
      "@786 = identity(@202) -> float_type, {128}, {1}\n",
      "@787 = identity(@201) -> float_type, {128}, {1}\n",
      "@788 = unknown:FusedBatchNormV3(@783,@784,@785,@786,@787) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@789 = transpose[dims={0, 3, 1, 2}](@788) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@790 = relu(@789) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@791 = transpose[dims={0, 2, 3, 1}](@790) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@792 = transpose[dims={0, 2, 3, 1}](@200) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@793 = transpose[dims={0, 3, 1, 2}](@792) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@794 = identity(@793) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@795 = transpose[dims={0, 2, 3, 1}](@794) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@796 = transpose[dims={0, 3, 1, 2}](@791) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@797 = transpose[dims={0, 3, 1, 2}](@795) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@798 = transpose[dims={3, 2, 0, 1}](@797) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@799 = transpose[dims={3, 2, 0, 1}](@797) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@800 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@796,@799) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@801 = transpose[dims={0, 2, 3, 1}](@800) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@802 = identity(@199) -> float_type, {512}, {1}\n",
      "@803 = transpose[dims={0, 3, 1, 2}](@801) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@804 = broadcast[axis=1,dims={1, 512, 28, 28}](@802) -> float_type, {1, 512, 28, 28}, {0, 1, 0, 0}\n",
      "@805 = add(@803,@804) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@806 = transpose[dims={0, 2, 3, 1}](@805) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@807 = identity(@198) -> float_type, {512}, {1}\n",
      "@808 = identity(@197) -> float_type, {512}, {1}\n",
      "@809 = identity(@196) -> float_type, {512}, {1}\n",
      "@810 = identity(@195) -> float_type, {512}, {1}\n",
      "@811 = unknown:FusedBatchNormV3(@806,@807,@808,@809,@810) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@812 = unknown:AddV2(@745,@811) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@813 = transpose[dims={0, 3, 1, 2}](@812) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@814 = relu(@813) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@815 = transpose[dims={0, 2, 3, 1}](@814) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@816 = transpose[dims={0, 2, 3, 1}](@194) -> float_type, {1, 512, 128, 1}, {65536, 128, 1, 65536}\n",
      "@817 = transpose[dims={0, 3, 1, 2}](@816) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@818 = identity(@817) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@819 = transpose[dims={0, 2, 3, 1}](@818) -> float_type, {1, 512, 128, 1}, {65536, 128, 1, 65536}\n",
      "@820 = transpose[dims={0, 3, 1, 2}](@815) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@821 = transpose[dims={0, 3, 1, 2}](@819) -> float_type, {1, 1, 512, 128}, {65536, 65536, 128, 1}\n",
      "@822 = transpose[dims={3, 2, 0, 1}](@821) -> float_type, {128, 512, 1, 1}, {1, 128, 65536, 65536}\n",
      "@823 = transpose[dims={3, 2, 0, 1}](@821) -> float_type, {128, 512, 1, 1}, {1, 128, 65536, 65536}\n",
      "@824 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@820,@823) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@825 = transpose[dims={0, 2, 3, 1}](@824) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@826 = identity(@193) -> float_type, {128}, {1}\n",
      "@827 = transpose[dims={0, 3, 1, 2}](@825) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@828 = broadcast[axis=1,dims={1, 128, 28, 28}](@826) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@829 = add(@827,@828) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@830 = transpose[dims={0, 2, 3, 1}](@829) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@831 = identity(@192) -> float_type, {128}, {1}\n",
      "@832 = identity(@191) -> float_type, {128}, {1}\n",
      "@833 = identity(@190) -> float_type, {128}, {1}\n",
      "@834 = identity(@189) -> float_type, {128}, {1}\n",
      "@835 = unknown:FusedBatchNormV3(@830,@831,@832,@833,@834) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@836 = transpose[dims={0, 3, 1, 2}](@835) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@837 = relu(@836) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@838 = transpose[dims={0, 2, 3, 1}](@837) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@839 = transpose[dims={0, 2, 3, 1}](@188) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@840 = transpose[dims={0, 3, 1, 2}](@839) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@841 = identity(@840) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@842 = transpose[dims={0, 2, 3, 1}](@841) -> float_type, {3, 128, 128, 3}, {49152, 128, 1, 16384}\n",
      "@843 = transpose[dims={0, 3, 1, 2}](@838) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@844 = transpose[dims={0, 3, 1, 2}](@842) -> float_type, {3, 3, 128, 128}, {49152, 16384, 128, 1}\n",
      "@845 = transpose[dims={3, 2, 0, 1}](@844) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@846 = transpose[dims={3, 2, 0, 1}](@844) -> float_type, {128, 128, 3, 3}, {1, 128, 49152, 16384}\n",
      "@847 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@843,@846) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@848 = transpose[dims={0, 2, 3, 1}](@847) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@849 = identity(@187) -> float_type, {128}, {1}\n",
      "@850 = transpose[dims={0, 3, 1, 2}](@848) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@851 = broadcast[axis=1,dims={1, 128, 28, 28}](@849) -> float_type, {1, 128, 28, 28}, {0, 1, 0, 0}\n",
      "@852 = add(@850,@851) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@853 = transpose[dims={0, 2, 3, 1}](@852) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@854 = identity(@186) -> float_type, {128}, {1}\n",
      "@855 = identity(@185) -> float_type, {128}, {1}\n",
      "@856 = identity(@184) -> float_type, {128}, {1}\n",
      "@857 = identity(@183) -> float_type, {128}, {1}\n",
      "@858 = unknown:FusedBatchNormV3(@853,@854,@855,@856,@857) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@859 = transpose[dims={0, 3, 1, 2}](@858) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@860 = relu(@859) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@861 = transpose[dims={0, 2, 3, 1}](@860) -> float_type, {1, 28, 28, 128}, {100352, 28, 1, 784}\n",
      "@862 = transpose[dims={0, 2, 3, 1}](@182) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@863 = transpose[dims={0, 3, 1, 2}](@862) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@864 = identity(@863) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@865 = transpose[dims={0, 2, 3, 1}](@864) -> float_type, {1, 128, 512, 1}, {65536, 512, 1, 65536}\n",
      "@866 = transpose[dims={0, 3, 1, 2}](@861) -> float_type, {1, 128, 28, 28}, {100352, 784, 28, 1}\n",
      "@867 = transpose[dims={0, 3, 1, 2}](@865) -> float_type, {1, 1, 128, 512}, {65536, 65536, 512, 1}\n",
      "@868 = transpose[dims={3, 2, 0, 1}](@867) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@869 = transpose[dims={3, 2, 0, 1}](@867) -> float_type, {512, 128, 1, 1}, {1, 512, 65536, 65536}\n",
      "@870 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@866,@869) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@871 = transpose[dims={0, 2, 3, 1}](@870) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@872 = identity(@181) -> float_type, {512}, {1}\n",
      "@873 = transpose[dims={0, 3, 1, 2}](@871) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@874 = broadcast[axis=1,dims={1, 512, 28, 28}](@872) -> float_type, {1, 512, 28, 28}, {0, 1, 0, 0}\n",
      "@875 = add(@873,@874) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@876 = transpose[dims={0, 2, 3, 1}](@875) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@877 = identity(@180) -> float_type, {512}, {1}\n",
      "@878 = identity(@179) -> float_type, {512}, {1}\n",
      "@879 = identity(@178) -> float_type, {512}, {1}\n",
      "@880 = identity(@177) -> float_type, {512}, {1}\n",
      "@881 = unknown:FusedBatchNormV3(@876,@877,@878,@879,@880) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@882 = unknown:AddV2(@815,@881) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@883 = transpose[dims={0, 3, 1, 2}](@882) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@884 = relu(@883) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@885 = transpose[dims={0, 2, 3, 1}](@884) -> float_type, {1, 28, 28, 512}, {401408, 28, 1, 784}\n",
      "@886 = transpose[dims={0, 2, 3, 1}](@176) -> float_type, {1, 512, 1024, 1}, {524288, 1024, 1, 524288}\n",
      "@887 = transpose[dims={0, 3, 1, 2}](@886) -> float_type, {1, 1, 512, 1024}, {524288, 524288, 1024, 1}\n",
      "@888 = identity(@887) -> float_type, {1, 1, 512, 1024}, {524288, 524288, 1024, 1}\n",
      "@889 = transpose[dims={0, 2, 3, 1}](@888) -> float_type, {1, 512, 1024, 1}, {524288, 1024, 1, 524288}\n",
      "@890 = transpose[dims={0, 3, 1, 2}](@885) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@891 = transpose[dims={0, 3, 1, 2}](@889) -> float_type, {1, 1, 512, 1024}, {524288, 524288, 1024, 1}\n",
      "@892 = transpose[dims={3, 2, 0, 1}](@891) -> float_type, {1024, 512, 1, 1}, {1, 1024, 524288, 524288}\n",
      "@893 = transpose[dims={3, 2, 0, 1}](@891) -> float_type, {1024, 512, 1, 1}, {1, 1024, 524288, 524288}\n",
      "@894 = convolution[padding={0, 0},stride={2, 2},dilation={1, 1},group=1,padding_mode=2](@890,@893) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@895 = transpose[dims={0, 2, 3, 1}](@894) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@896 = identity(@175) -> float_type, {1024}, {1}\n",
      "@897 = transpose[dims={0, 3, 1, 2}](@895) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@898 = broadcast[axis=1,dims={1, 1024, 14, 14}](@896) -> float_type, {1, 1024, 14, 14}, {0, 1, 0, 0}\n",
      "@899 = add(@897,@898) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@900 = transpose[dims={0, 2, 3, 1}](@899) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@901 = identity(@174) -> float_type, {1024}, {1}\n",
      "@902 = identity(@173) -> float_type, {1024}, {1}\n",
      "@903 = identity(@172) -> float_type, {1024}, {1}\n",
      "@904 = identity(@171) -> float_type, {1024}, {1}\n",
      "@905 = unknown:FusedBatchNormV3(@900,@901,@902,@903,@904) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@906 = transpose[dims={0, 2, 3, 1}](@170) -> float_type, {1, 512, 256, 1}, {131072, 256, 1, 131072}\n",
      "@907 = transpose[dims={0, 3, 1, 2}](@906) -> float_type, {1, 1, 512, 256}, {131072, 131072, 256, 1}\n",
      "@908 = identity(@907) -> float_type, {1, 1, 512, 256}, {131072, 131072, 256, 1}\n",
      "@909 = transpose[dims={0, 2, 3, 1}](@908) -> float_type, {1, 512, 256, 1}, {131072, 256, 1, 131072}\n",
      "@910 = transpose[dims={0, 3, 1, 2}](@885) -> float_type, {1, 512, 28, 28}, {401408, 784, 28, 1}\n",
      "@911 = transpose[dims={0, 3, 1, 2}](@909) -> float_type, {1, 1, 512, 256}, {131072, 131072, 256, 1}\n",
      "@912 = transpose[dims={3, 2, 0, 1}](@911) -> float_type, {256, 512, 1, 1}, {1, 256, 131072, 131072}\n",
      "@913 = transpose[dims={3, 2, 0, 1}](@911) -> float_type, {256, 512, 1, 1}, {1, 256, 131072, 131072}\n",
      "@914 = convolution[padding={0, 0},stride={2, 2},dilation={1, 1},group=1,padding_mode=2](@910,@913) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@915 = transpose[dims={0, 2, 3, 1}](@914) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@916 = identity(@169) -> float_type, {256}, {1}\n",
      "@917 = transpose[dims={0, 3, 1, 2}](@915) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@918 = broadcast[axis=1,dims={1, 256, 14, 14}](@916) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@919 = add(@917,@918) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@920 = transpose[dims={0, 2, 3, 1}](@919) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@921 = identity(@168) -> float_type, {256}, {1}\n",
      "@922 = identity(@167) -> float_type, {256}, {1}\n",
      "@923 = identity(@166) -> float_type, {256}, {1}\n",
      "@924 = identity(@165) -> float_type, {256}, {1}\n",
      "@925 = unknown:FusedBatchNormV3(@920,@921,@922,@923,@924) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@926 = transpose[dims={0, 3, 1, 2}](@925) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@927 = relu(@926) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@928 = transpose[dims={0, 2, 3, 1}](@927) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@929 = transpose[dims={0, 2, 3, 1}](@164) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@930 = transpose[dims={0, 3, 1, 2}](@929) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@931 = identity(@930) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@932 = transpose[dims={0, 2, 3, 1}](@931) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@933 = transpose[dims={0, 3, 1, 2}](@928) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@934 = transpose[dims={0, 3, 1, 2}](@932) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@935 = transpose[dims={3, 2, 0, 1}](@934) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@936 = transpose[dims={3, 2, 0, 1}](@934) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@937 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@933,@936) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@938 = transpose[dims={0, 2, 3, 1}](@937) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@939 = identity(@163) -> float_type, {256}, {1}\n",
      "@940 = transpose[dims={0, 3, 1, 2}](@938) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@941 = broadcast[axis=1,dims={1, 256, 14, 14}](@939) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@942 = add(@940,@941) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@943 = transpose[dims={0, 2, 3, 1}](@942) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@944 = identity(@162) -> float_type, {256}, {1}\n",
      "@945 = identity(@161) -> float_type, {256}, {1}\n",
      "@946 = identity(@160) -> float_type, {256}, {1}\n",
      "@947 = identity(@159) -> float_type, {256}, {1}\n",
      "@948 = unknown:FusedBatchNormV3(@943,@944,@945,@946,@947) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@949 = transpose[dims={0, 3, 1, 2}](@948) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@950 = relu(@949) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@951 = transpose[dims={0, 2, 3, 1}](@950) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@952 = transpose[dims={0, 2, 3, 1}](@158) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@953 = transpose[dims={0, 3, 1, 2}](@952) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@954 = identity(@953) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@955 = transpose[dims={0, 2, 3, 1}](@954) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@956 = transpose[dims={0, 3, 1, 2}](@951) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@957 = transpose[dims={0, 3, 1, 2}](@955) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@958 = transpose[dims={3, 2, 0, 1}](@957) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@959 = transpose[dims={3, 2, 0, 1}](@957) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@960 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@956,@959) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@961 = transpose[dims={0, 2, 3, 1}](@960) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@962 = identity(@157) -> float_type, {1024}, {1}\n",
      "@963 = transpose[dims={0, 3, 1, 2}](@961) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@964 = broadcast[axis=1,dims={1, 1024, 14, 14}](@962) -> float_type, {1, 1024, 14, 14}, {0, 1, 0, 0}\n",
      "@965 = add(@963,@964) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@966 = transpose[dims={0, 2, 3, 1}](@965) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@967 = identity(@156) -> float_type, {1024}, {1}\n",
      "@968 = identity(@155) -> float_type, {1024}, {1}\n",
      "@969 = identity(@154) -> float_type, {1024}, {1}\n",
      "@970 = identity(@153) -> float_type, {1024}, {1}\n",
      "@971 = unknown:FusedBatchNormV3(@966,@967,@968,@969,@970) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@972 = unknown:AddV2(@905,@971) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@973 = transpose[dims={0, 3, 1, 2}](@972) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@974 = relu(@973) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@975 = transpose[dims={0, 2, 3, 1}](@974) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@976 = transpose[dims={0, 2, 3, 1}](@152) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@977 = transpose[dims={0, 3, 1, 2}](@976) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@978 = identity(@977) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@979 = transpose[dims={0, 2, 3, 1}](@978) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@980 = transpose[dims={0, 3, 1, 2}](@975) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@981 = transpose[dims={0, 3, 1, 2}](@979) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@982 = transpose[dims={3, 2, 0, 1}](@981) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@983 = transpose[dims={3, 2, 0, 1}](@981) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@984 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@980,@983) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@985 = transpose[dims={0, 2, 3, 1}](@984) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@986 = identity(@151) -> float_type, {256}, {1}\n",
      "@987 = transpose[dims={0, 3, 1, 2}](@985) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@988 = broadcast[axis=1,dims={1, 256, 14, 14}](@986) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@989 = add(@987,@988) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@990 = transpose[dims={0, 2, 3, 1}](@989) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@991 = identity(@150) -> float_type, {256}, {1}\n",
      "@992 = identity(@149) -> float_type, {256}, {1}\n",
      "@993 = identity(@148) -> float_type, {256}, {1}\n",
      "@994 = identity(@147) -> float_type, {256}, {1}\n",
      "@995 = unknown:FusedBatchNormV3(@990,@991,@992,@993,@994) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@996 = transpose[dims={0, 3, 1, 2}](@995) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@997 = relu(@996) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@998 = transpose[dims={0, 2, 3, 1}](@997) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@999 = transpose[dims={0, 2, 3, 1}](@146) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1000 = transpose[dims={0, 3, 1, 2}](@999) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1001 = identity(@1000) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1002 = transpose[dims={0, 2, 3, 1}](@1001) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1003 = transpose[dims={0, 3, 1, 2}](@998) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1004 = transpose[dims={0, 3, 1, 2}](@1002) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1005 = transpose[dims={3, 2, 0, 1}](@1004) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1006 = transpose[dims={3, 2, 0, 1}](@1004) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1007 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1003,@1006) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1008 = transpose[dims={0, 2, 3, 1}](@1007) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1009 = identity(@145) -> float_type, {256}, {1}\n",
      "@1010 = transpose[dims={0, 3, 1, 2}](@1008) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1011 = broadcast[axis=1,dims={1, 256, 14, 14}](@1009) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1012 = add(@1010,@1011) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1013 = transpose[dims={0, 2, 3, 1}](@1012) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1014 = identity(@144) -> float_type, {256}, {1}\n",
      "@1015 = identity(@143) -> float_type, {256}, {1}\n",
      "@1016 = identity(@142) -> float_type, {256}, {1}\n",
      "@1017 = identity(@141) -> float_type, {256}, {1}\n",
      "@1018 = unknown:FusedBatchNormV3(@1013,@1014,@1015,@1016,@1017) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1019 = transpose[dims={0, 3, 1, 2}](@1018) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1020 = relu(@1019) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1021 = transpose[dims={0, 2, 3, 1}](@1020) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1022 = transpose[dims={0, 2, 3, 1}](@140) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1023 = transpose[dims={0, 3, 1, 2}](@1022) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1024 = identity(@1023) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1025 = transpose[dims={0, 2, 3, 1}](@1024) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1026 = transpose[dims={0, 3, 1, 2}](@1021) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1027 = transpose[dims={0, 3, 1, 2}](@1025) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1028 = transpose[dims={3, 2, 0, 1}](@1027) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1029 = transpose[dims={3, 2, 0, 1}](@1027) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1030 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1026,@1029) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1031 = transpose[dims={0, 2, 3, 1}](@1030) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1032 = identity(@139) -> float_type, {1024}, {1}\n",
      "@1033 = transpose[dims={0, 3, 1, 2}](@1031) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1034 = broadcast[axis=1,dims={1, 1024, 14, 14}](@1032) -> float_type, {1, 1024, 14, 14}, {0, 1, 0, 0}\n",
      "@1035 = add(@1033,@1034) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1036 = transpose[dims={0, 2, 3, 1}](@1035) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1037 = identity(@138) -> float_type, {1024}, {1}\n",
      "@1038 = identity(@137) -> float_type, {1024}, {1}\n",
      "@1039 = identity(@136) -> float_type, {1024}, {1}\n",
      "@1040 = identity(@135) -> float_type, {1024}, {1}\n",
      "@1041 = unknown:FusedBatchNormV3(@1036,@1037,@1038,@1039,@1040) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1042 = unknown:AddV2(@975,@1041) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1043 = transpose[dims={0, 3, 1, 2}](@1042) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1044 = relu(@1043) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1045 = transpose[dims={0, 2, 3, 1}](@1044) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1046 = transpose[dims={0, 2, 3, 1}](@134) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1047 = transpose[dims={0, 3, 1, 2}](@1046) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1048 = identity(@1047) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1049 = transpose[dims={0, 2, 3, 1}](@1048) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1050 = transpose[dims={0, 3, 1, 2}](@1045) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1051 = transpose[dims={0, 3, 1, 2}](@1049) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1052 = transpose[dims={3, 2, 0, 1}](@1051) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1053 = transpose[dims={3, 2, 0, 1}](@1051) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1054 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1050,@1053) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1055 = transpose[dims={0, 2, 3, 1}](@1054) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1056 = identity(@133) -> float_type, {256}, {1}\n",
      "@1057 = transpose[dims={0, 3, 1, 2}](@1055) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1058 = broadcast[axis=1,dims={1, 256, 14, 14}](@1056) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1059 = add(@1057,@1058) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1060 = transpose[dims={0, 2, 3, 1}](@1059) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1061 = identity(@132) -> float_type, {256}, {1}\n",
      "@1062 = identity(@131) -> float_type, {256}, {1}\n",
      "@1063 = identity(@130) -> float_type, {256}, {1}\n",
      "@1064 = identity(@129) -> float_type, {256}, {1}\n",
      "@1065 = unknown:FusedBatchNormV3(@1060,@1061,@1062,@1063,@1064) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1066 = transpose[dims={0, 3, 1, 2}](@1065) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1067 = relu(@1066) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1068 = transpose[dims={0, 2, 3, 1}](@1067) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1069 = transpose[dims={0, 2, 3, 1}](@128) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1070 = transpose[dims={0, 3, 1, 2}](@1069) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1071 = identity(@1070) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1072 = transpose[dims={0, 2, 3, 1}](@1071) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1073 = transpose[dims={0, 3, 1, 2}](@1068) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1074 = transpose[dims={0, 3, 1, 2}](@1072) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1075 = transpose[dims={3, 2, 0, 1}](@1074) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1076 = transpose[dims={3, 2, 0, 1}](@1074) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1077 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1073,@1076) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1078 = transpose[dims={0, 2, 3, 1}](@1077) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1079 = identity(@127) -> float_type, {256}, {1}\n",
      "@1080 = transpose[dims={0, 3, 1, 2}](@1078) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1081 = broadcast[axis=1,dims={1, 256, 14, 14}](@1079) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1082 = add(@1080,@1081) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1083 = transpose[dims={0, 2, 3, 1}](@1082) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1084 = identity(@126) -> float_type, {256}, {1}\n",
      "@1085 = identity(@125) -> float_type, {256}, {1}\n",
      "@1086 = identity(@124) -> float_type, {256}, {1}\n",
      "@1087 = identity(@123) -> float_type, {256}, {1}\n",
      "@1088 = unknown:FusedBatchNormV3(@1083,@1084,@1085,@1086,@1087) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1089 = transpose[dims={0, 3, 1, 2}](@1088) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1090 = relu(@1089) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1091 = transpose[dims={0, 2, 3, 1}](@1090) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1092 = transpose[dims={0, 2, 3, 1}](@122) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1093 = transpose[dims={0, 3, 1, 2}](@1092) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1094 = identity(@1093) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1095 = transpose[dims={0, 2, 3, 1}](@1094) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1096 = transpose[dims={0, 3, 1, 2}](@1091) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1097 = transpose[dims={0, 3, 1, 2}](@1095) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1098 = transpose[dims={3, 2, 0, 1}](@1097) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1099 = transpose[dims={3, 2, 0, 1}](@1097) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1100 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1096,@1099) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1101 = transpose[dims={0, 2, 3, 1}](@1100) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1102 = identity(@121) -> float_type, {1024}, {1}\n",
      "@1103 = transpose[dims={0, 3, 1, 2}](@1101) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1104 = broadcast[axis=1,dims={1, 1024, 14, 14}](@1102) -> float_type, {1, 1024, 14, 14}, {0, 1, 0, 0}\n",
      "@1105 = add(@1103,@1104) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1106 = transpose[dims={0, 2, 3, 1}](@1105) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1107 = identity(@120) -> float_type, {1024}, {1}\n",
      "@1108 = identity(@119) -> float_type, {1024}, {1}\n",
      "@1109 = identity(@118) -> float_type, {1024}, {1}\n",
      "@1110 = identity(@117) -> float_type, {1024}, {1}\n",
      "@1111 = unknown:FusedBatchNormV3(@1106,@1107,@1108,@1109,@1110) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1112 = unknown:AddV2(@1045,@1111) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1113 = transpose[dims={0, 3, 1, 2}](@1112) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1114 = relu(@1113) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1115 = transpose[dims={0, 2, 3, 1}](@1114) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1116 = transpose[dims={0, 2, 3, 1}](@116) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1117 = transpose[dims={0, 3, 1, 2}](@1116) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1118 = identity(@1117) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1119 = transpose[dims={0, 2, 3, 1}](@1118) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1120 = transpose[dims={0, 3, 1, 2}](@1115) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1121 = transpose[dims={0, 3, 1, 2}](@1119) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1122 = transpose[dims={3, 2, 0, 1}](@1121) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1123 = transpose[dims={3, 2, 0, 1}](@1121) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1124 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1120,@1123) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1125 = transpose[dims={0, 2, 3, 1}](@1124) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1126 = identity(@115) -> float_type, {256}, {1}\n",
      "@1127 = transpose[dims={0, 3, 1, 2}](@1125) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1128 = broadcast[axis=1,dims={1, 256, 14, 14}](@1126) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1129 = add(@1127,@1128) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1130 = transpose[dims={0, 2, 3, 1}](@1129) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1131 = identity(@114) -> float_type, {256}, {1}\n",
      "@1132 = identity(@113) -> float_type, {256}, {1}\n",
      "@1133 = identity(@112) -> float_type, {256}, {1}\n",
      "@1134 = identity(@111) -> float_type, {256}, {1}\n",
      "@1135 = unknown:FusedBatchNormV3(@1130,@1131,@1132,@1133,@1134) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1136 = transpose[dims={0, 3, 1, 2}](@1135) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1137 = relu(@1136) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1138 = transpose[dims={0, 2, 3, 1}](@1137) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1139 = transpose[dims={0, 2, 3, 1}](@110) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1140 = transpose[dims={0, 3, 1, 2}](@1139) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1141 = identity(@1140) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1142 = transpose[dims={0, 2, 3, 1}](@1141) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1143 = transpose[dims={0, 3, 1, 2}](@1138) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1144 = transpose[dims={0, 3, 1, 2}](@1142) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1145 = transpose[dims={3, 2, 0, 1}](@1144) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1146 = transpose[dims={3, 2, 0, 1}](@1144) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1147 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1143,@1146) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1148 = transpose[dims={0, 2, 3, 1}](@1147) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1149 = identity(@109) -> float_type, {256}, {1}\n",
      "@1150 = transpose[dims={0, 3, 1, 2}](@1148) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1151 = broadcast[axis=1,dims={1, 256, 14, 14}](@1149) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1152 = add(@1150,@1151) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1153 = transpose[dims={0, 2, 3, 1}](@1152) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1154 = identity(@108) -> float_type, {256}, {1}\n",
      "@1155 = identity(@107) -> float_type, {256}, {1}\n",
      "@1156 = identity(@106) -> float_type, {256}, {1}\n",
      "@1157 = identity(@105) -> float_type, {256}, {1}\n",
      "@1158 = unknown:FusedBatchNormV3(@1153,@1154,@1155,@1156,@1157) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1159 = transpose[dims={0, 3, 1, 2}](@1158) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1160 = relu(@1159) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1161 = transpose[dims={0, 2, 3, 1}](@1160) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1162 = transpose[dims={0, 2, 3, 1}](@104) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1163 = transpose[dims={0, 3, 1, 2}](@1162) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1164 = identity(@1163) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1165 = transpose[dims={0, 2, 3, 1}](@1164) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1166 = transpose[dims={0, 3, 1, 2}](@1161) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1167 = transpose[dims={0, 3, 1, 2}](@1165) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1168 = transpose[dims={3, 2, 0, 1}](@1167) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1169 = transpose[dims={3, 2, 0, 1}](@1167) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1170 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1166,@1169) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1171 = transpose[dims={0, 2, 3, 1}](@1170) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1172 = identity(@103) -> float_type, {1024}, {1}\n",
      "@1173 = transpose[dims={0, 3, 1, 2}](@1171) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1174 = broadcast[axis=1,dims={1, 1024, 14, 14}](@1172) -> float_type, {1, 1024, 14, 14}, {0, 1, 0, 0}\n",
      "@1175 = add(@1173,@1174) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1176 = transpose[dims={0, 2, 3, 1}](@1175) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1177 = identity(@102) -> float_type, {1024}, {1}\n",
      "@1178 = identity(@101) -> float_type, {1024}, {1}\n",
      "@1179 = identity(@100) -> float_type, {1024}, {1}\n",
      "@1180 = identity(@99) -> float_type, {1024}, {1}\n",
      "@1181 = unknown:FusedBatchNormV3(@1176,@1177,@1178,@1179,@1180) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1182 = unknown:AddV2(@1115,@1181) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1183 = transpose[dims={0, 3, 1, 2}](@1182) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1184 = relu(@1183) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1185 = transpose[dims={0, 2, 3, 1}](@1184) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1186 = transpose[dims={0, 2, 3, 1}](@98) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1187 = transpose[dims={0, 3, 1, 2}](@1186) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1188 = identity(@1187) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1189 = transpose[dims={0, 2, 3, 1}](@1188) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1190 = transpose[dims={0, 3, 1, 2}](@1185) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1191 = transpose[dims={0, 3, 1, 2}](@1189) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1192 = transpose[dims={3, 2, 0, 1}](@1191) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1193 = transpose[dims={3, 2, 0, 1}](@1191) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1194 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1190,@1193) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1195 = transpose[dims={0, 2, 3, 1}](@1194) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1196 = identity(@97) -> float_type, {256}, {1}\n",
      "@1197 = transpose[dims={0, 3, 1, 2}](@1195) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1198 = broadcast[axis=1,dims={1, 256, 14, 14}](@1196) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1199 = add(@1197,@1198) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1200 = transpose[dims={0, 2, 3, 1}](@1199) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1201 = identity(@96) -> float_type, {256}, {1}\n",
      "@1202 = identity(@95) -> float_type, {256}, {1}\n",
      "@1203 = identity(@94) -> float_type, {256}, {1}\n",
      "@1204 = identity(@93) -> float_type, {256}, {1}\n",
      "@1205 = unknown:FusedBatchNormV3(@1200,@1201,@1202,@1203,@1204) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1206 = transpose[dims={0, 3, 1, 2}](@1205) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1207 = relu(@1206) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1208 = transpose[dims={0, 2, 3, 1}](@1207) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1209 = transpose[dims={0, 2, 3, 1}](@92) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1210 = transpose[dims={0, 3, 1, 2}](@1209) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1211 = identity(@1210) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1212 = transpose[dims={0, 2, 3, 1}](@1211) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1213 = transpose[dims={0, 3, 1, 2}](@1208) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1214 = transpose[dims={0, 3, 1, 2}](@1212) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1215 = transpose[dims={3, 2, 0, 1}](@1214) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1216 = transpose[dims={3, 2, 0, 1}](@1214) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1217 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1213,@1216) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1218 = transpose[dims={0, 2, 3, 1}](@1217) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1219 = identity(@91) -> float_type, {256}, {1}\n",
      "@1220 = transpose[dims={0, 3, 1, 2}](@1218) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1221 = broadcast[axis=1,dims={1, 256, 14, 14}](@1219) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1222 = add(@1220,@1221) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1223 = transpose[dims={0, 2, 3, 1}](@1222) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1224 = identity(@90) -> float_type, {256}, {1}\n",
      "@1225 = identity(@89) -> float_type, {256}, {1}\n",
      "@1226 = identity(@88) -> float_type, {256}, {1}\n",
      "@1227 = identity(@87) -> float_type, {256}, {1}\n",
      "@1228 = unknown:FusedBatchNormV3(@1223,@1224,@1225,@1226,@1227) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1229 = transpose[dims={0, 3, 1, 2}](@1228) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1230 = relu(@1229) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1231 = transpose[dims={0, 2, 3, 1}](@1230) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1232 = transpose[dims={0, 2, 3, 1}](@86) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1233 = transpose[dims={0, 3, 1, 2}](@1232) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1234 = identity(@1233) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1235 = transpose[dims={0, 2, 3, 1}](@1234) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1236 = transpose[dims={0, 3, 1, 2}](@1231) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1237 = transpose[dims={0, 3, 1, 2}](@1235) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1238 = transpose[dims={3, 2, 0, 1}](@1237) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1239 = transpose[dims={3, 2, 0, 1}](@1237) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1240 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1236,@1239) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1241 = transpose[dims={0, 2, 3, 1}](@1240) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1242 = identity(@85) -> float_type, {1024}, {1}\n",
      "@1243 = transpose[dims={0, 3, 1, 2}](@1241) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1244 = broadcast[axis=1,dims={1, 1024, 14, 14}](@1242) -> float_type, {1, 1024, 14, 14}, {0, 1, 0, 0}\n",
      "@1245 = add(@1243,@1244) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1246 = transpose[dims={0, 2, 3, 1}](@1245) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1247 = identity(@84) -> float_type, {1024}, {1}\n",
      "@1248 = identity(@83) -> float_type, {1024}, {1}\n",
      "@1249 = identity(@82) -> float_type, {1024}, {1}\n",
      "@1250 = identity(@81) -> float_type, {1024}, {1}\n",
      "@1251 = unknown:FusedBatchNormV3(@1246,@1247,@1248,@1249,@1250) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1252 = unknown:AddV2(@1185,@1251) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1253 = transpose[dims={0, 3, 1, 2}](@1252) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1254 = relu(@1253) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1255 = transpose[dims={0, 2, 3, 1}](@1254) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1256 = transpose[dims={0, 2, 3, 1}](@80) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1257 = transpose[dims={0, 3, 1, 2}](@1256) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1258 = identity(@1257) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1259 = transpose[dims={0, 2, 3, 1}](@1258) -> float_type, {1, 1024, 256, 1}, {262144, 256, 1, 262144}\n",
      "@1260 = transpose[dims={0, 3, 1, 2}](@1255) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1261 = transpose[dims={0, 3, 1, 2}](@1259) -> float_type, {1, 1, 1024, 256}, {262144, 262144, 256, 1}\n",
      "@1262 = transpose[dims={3, 2, 0, 1}](@1261) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1263 = transpose[dims={3, 2, 0, 1}](@1261) -> float_type, {256, 1024, 1, 1}, {1, 256, 262144, 262144}\n",
      "@1264 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1260,@1263) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1265 = transpose[dims={0, 2, 3, 1}](@1264) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1266 = identity(@79) -> float_type, {256}, {1}\n",
      "@1267 = transpose[dims={0, 3, 1, 2}](@1265) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1268 = broadcast[axis=1,dims={1, 256, 14, 14}](@1266) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1269 = add(@1267,@1268) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1270 = transpose[dims={0, 2, 3, 1}](@1269) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1271 = identity(@78) -> float_type, {256}, {1}\n",
      "@1272 = identity(@77) -> float_type, {256}, {1}\n",
      "@1273 = identity(@76) -> float_type, {256}, {1}\n",
      "@1274 = identity(@75) -> float_type, {256}, {1}\n",
      "@1275 = unknown:FusedBatchNormV3(@1270,@1271,@1272,@1273,@1274) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1276 = transpose[dims={0, 3, 1, 2}](@1275) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1277 = relu(@1276) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1278 = transpose[dims={0, 2, 3, 1}](@1277) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1279 = transpose[dims={0, 2, 3, 1}](@74) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1280 = transpose[dims={0, 3, 1, 2}](@1279) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1281 = identity(@1280) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1282 = transpose[dims={0, 2, 3, 1}](@1281) -> float_type, {3, 256, 256, 3}, {196608, 256, 1, 65536}\n",
      "@1283 = transpose[dims={0, 3, 1, 2}](@1278) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1284 = transpose[dims={0, 3, 1, 2}](@1282) -> float_type, {3, 3, 256, 256}, {196608, 65536, 256, 1}\n",
      "@1285 = transpose[dims={3, 2, 0, 1}](@1284) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1286 = transpose[dims={3, 2, 0, 1}](@1284) -> float_type, {256, 256, 3, 3}, {1, 256, 196608, 65536}\n",
      "@1287 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1283,@1286) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1288 = transpose[dims={0, 2, 3, 1}](@1287) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1289 = identity(@73) -> float_type, {256}, {1}\n",
      "@1290 = transpose[dims={0, 3, 1, 2}](@1288) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1291 = broadcast[axis=1,dims={1, 256, 14, 14}](@1289) -> float_type, {1, 256, 14, 14}, {0, 1, 0, 0}\n",
      "@1292 = add(@1290,@1291) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1293 = transpose[dims={0, 2, 3, 1}](@1292) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1294 = identity(@72) -> float_type, {256}, {1}\n",
      "@1295 = identity(@71) -> float_type, {256}, {1}\n",
      "@1296 = identity(@70) -> float_type, {256}, {1}\n",
      "@1297 = identity(@69) -> float_type, {256}, {1}\n",
      "@1298 = unknown:FusedBatchNormV3(@1293,@1294,@1295,@1296,@1297) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1299 = transpose[dims={0, 3, 1, 2}](@1298) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1300 = relu(@1299) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1301 = transpose[dims={0, 2, 3, 1}](@1300) -> float_type, {1, 14, 14, 256}, {50176, 14, 1, 196}\n",
      "@1302 = transpose[dims={0, 2, 3, 1}](@68) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1303 = transpose[dims={0, 3, 1, 2}](@1302) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1304 = identity(@1303) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1305 = transpose[dims={0, 2, 3, 1}](@1304) -> float_type, {1, 256, 1024, 1}, {262144, 1024, 1, 262144}\n",
      "@1306 = transpose[dims={0, 3, 1, 2}](@1301) -> float_type, {1, 256, 14, 14}, {50176, 196, 14, 1}\n",
      "@1307 = transpose[dims={0, 3, 1, 2}](@1305) -> float_type, {1, 1, 256, 1024}, {262144, 262144, 1024, 1}\n",
      "@1308 = transpose[dims={3, 2, 0, 1}](@1307) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1309 = transpose[dims={3, 2, 0, 1}](@1307) -> float_type, {1024, 256, 1, 1}, {1, 1024, 262144, 262144}\n",
      "@1310 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1306,@1309) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1311 = transpose[dims={0, 2, 3, 1}](@1310) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1312 = identity(@67) -> float_type, {1024}, {1}\n",
      "@1313 = transpose[dims={0, 3, 1, 2}](@1311) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1314 = broadcast[axis=1,dims={1, 1024, 14, 14}](@1312) -> float_type, {1, 1024, 14, 14}, {0, 1, 0, 0}\n",
      "@1315 = add(@1313,@1314) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1316 = transpose[dims={0, 2, 3, 1}](@1315) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1317 = identity(@66) -> float_type, {1024}, {1}\n",
      "@1318 = identity(@65) -> float_type, {1024}, {1}\n",
      "@1319 = identity(@64) -> float_type, {1024}, {1}\n",
      "@1320 = identity(@63) -> float_type, {1024}, {1}\n",
      "@1321 = unknown:FusedBatchNormV3(@1316,@1317,@1318,@1319,@1320) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1322 = unknown:AddV2(@1255,@1321) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1323 = transpose[dims={0, 3, 1, 2}](@1322) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1324 = relu(@1323) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1325 = transpose[dims={0, 2, 3, 1}](@1324) -> float_type, {1, 14, 14, 1024}, {200704, 14, 1, 196}\n",
      "@1326 = transpose[dims={0, 2, 3, 1}](@62) -> float_type, {1, 1024, 2048, 1}, {2097152, 2048, 1, 2097152}\n",
      "@1327 = transpose[dims={0, 3, 1, 2}](@1326) -> float_type, {1, 1, 1024, 2048}, {2097152, 2097152, 2048, 1}\n",
      "@1328 = identity(@1327) -> float_type, {1, 1, 1024, 2048}, {2097152, 2097152, 2048, 1}\n",
      "@1329 = transpose[dims={0, 2, 3, 1}](@1328) -> float_type, {1, 1024, 2048, 1}, {2097152, 2048, 1, 2097152}\n",
      "@1330 = transpose[dims={0, 3, 1, 2}](@1325) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1331 = transpose[dims={0, 3, 1, 2}](@1329) -> float_type, {1, 1, 1024, 2048}, {2097152, 2097152, 2048, 1}\n",
      "@1332 = transpose[dims={3, 2, 0, 1}](@1331) -> float_type, {2048, 1024, 1, 1}, {1, 2048, 2097152, 2097152}\n",
      "@1333 = transpose[dims={3, 2, 0, 1}](@1331) -> float_type, {2048, 1024, 1, 1}, {1, 2048, 2097152, 2097152}\n",
      "@1334 = convolution[padding={0, 0},stride={2, 2},dilation={1, 1},group=1,padding_mode=2](@1330,@1333) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1335 = transpose[dims={0, 2, 3, 1}](@1334) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1336 = identity(@61) -> float_type, {2048}, {1}\n",
      "@1337 = transpose[dims={0, 3, 1, 2}](@1335) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1338 = broadcast[axis=1,dims={1, 2048, 7, 7}](@1336) -> float_type, {1, 2048, 7, 7}, {0, 1, 0, 0}\n",
      "@1339 = add(@1337,@1338) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1340 = transpose[dims={0, 2, 3, 1}](@1339) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1341 = identity(@60) -> float_type, {2048}, {1}\n",
      "@1342 = identity(@59) -> float_type, {2048}, {1}\n",
      "@1343 = identity(@58) -> float_type, {2048}, {1}\n",
      "@1344 = identity(@57) -> float_type, {2048}, {1}\n",
      "@1345 = unknown:FusedBatchNormV3(@1340,@1341,@1342,@1343,@1344) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1346 = transpose[dims={0, 2, 3, 1}](@56) -> float_type, {1, 1024, 512, 1}, {524288, 512, 1, 524288}\n",
      "@1347 = transpose[dims={0, 3, 1, 2}](@1346) -> float_type, {1, 1, 1024, 512}, {524288, 524288, 512, 1}\n",
      "@1348 = identity(@1347) -> float_type, {1, 1, 1024, 512}, {524288, 524288, 512, 1}\n",
      "@1349 = transpose[dims={0, 2, 3, 1}](@1348) -> float_type, {1, 1024, 512, 1}, {524288, 512, 1, 524288}\n",
      "@1350 = transpose[dims={0, 3, 1, 2}](@1325) -> float_type, {1, 1024, 14, 14}, {200704, 196, 14, 1}\n",
      "@1351 = transpose[dims={0, 3, 1, 2}](@1349) -> float_type, {1, 1, 1024, 512}, {524288, 524288, 512, 1}\n",
      "@1352 = transpose[dims={3, 2, 0, 1}](@1351) -> float_type, {512, 1024, 1, 1}, {1, 512, 524288, 524288}\n",
      "@1353 = transpose[dims={3, 2, 0, 1}](@1351) -> float_type, {512, 1024, 1, 1}, {1, 512, 524288, 524288}\n",
      "@1354 = convolution[padding={0, 0},stride={2, 2},dilation={1, 1},group=1,padding_mode=2](@1350,@1353) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1355 = transpose[dims={0, 2, 3, 1}](@1354) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1356 = identity(@55) -> float_type, {512}, {1}\n",
      "@1357 = transpose[dims={0, 3, 1, 2}](@1355) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1358 = broadcast[axis=1,dims={1, 512, 7, 7}](@1356) -> float_type, {1, 512, 7, 7}, {0, 1, 0, 0}\n",
      "@1359 = add(@1357,@1358) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1360 = transpose[dims={0, 2, 3, 1}](@1359) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1361 = identity(@54) -> float_type, {512}, {1}\n",
      "@1362 = identity(@53) -> float_type, {512}, {1}\n",
      "@1363 = identity(@52) -> float_type, {512}, {1}\n",
      "@1364 = identity(@51) -> float_type, {512}, {1}\n",
      "@1365 = unknown:FusedBatchNormV3(@1360,@1361,@1362,@1363,@1364) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1366 = transpose[dims={0, 3, 1, 2}](@1365) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1367 = relu(@1366) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1368 = transpose[dims={0, 2, 3, 1}](@1367) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1369 = transpose[dims={0, 2, 3, 1}](@50) -> float_type, {3, 512, 512, 3}, {786432, 512, 1, 262144}\n",
      "@1370 = transpose[dims={0, 3, 1, 2}](@1369) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1371 = identity(@1370) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1372 = transpose[dims={0, 2, 3, 1}](@1371) -> float_type, {3, 512, 512, 3}, {786432, 512, 1, 262144}\n",
      "@1373 = transpose[dims={0, 3, 1, 2}](@1368) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1374 = transpose[dims={0, 3, 1, 2}](@1372) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1375 = transpose[dims={3, 2, 0, 1}](@1374) -> float_type, {512, 512, 3, 3}, {1, 512, 786432, 262144}\n",
      "@1376 = transpose[dims={3, 2, 0, 1}](@1374) -> float_type, {512, 512, 3, 3}, {1, 512, 786432, 262144}\n",
      "@1377 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1373,@1376) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1378 = transpose[dims={0, 2, 3, 1}](@1377) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1379 = identity(@49) -> float_type, {512}, {1}\n",
      "@1380 = transpose[dims={0, 3, 1, 2}](@1378) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1381 = broadcast[axis=1,dims={1, 512, 7, 7}](@1379) -> float_type, {1, 512, 7, 7}, {0, 1, 0, 0}\n",
      "@1382 = add(@1380,@1381) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1383 = transpose[dims={0, 2, 3, 1}](@1382) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1384 = identity(@48) -> float_type, {512}, {1}\n",
      "@1385 = identity(@47) -> float_type, {512}, {1}\n",
      "@1386 = identity(@46) -> float_type, {512}, {1}\n",
      "@1387 = identity(@45) -> float_type, {512}, {1}\n",
      "@1388 = unknown:FusedBatchNormV3(@1383,@1384,@1385,@1386,@1387) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1389 = transpose[dims={0, 3, 1, 2}](@1388) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1390 = relu(@1389) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1391 = transpose[dims={0, 2, 3, 1}](@1390) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1392 = transpose[dims={0, 2, 3, 1}](@44) -> float_type, {1, 512, 2048, 1}, {1048576, 2048, 1, 1048576}\n",
      "@1393 = transpose[dims={0, 3, 1, 2}](@1392) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1394 = identity(@1393) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1395 = transpose[dims={0, 2, 3, 1}](@1394) -> float_type, {1, 512, 2048, 1}, {1048576, 2048, 1, 1048576}\n",
      "@1396 = transpose[dims={0, 3, 1, 2}](@1391) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1397 = transpose[dims={0, 3, 1, 2}](@1395) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1398 = transpose[dims={3, 2, 0, 1}](@1397) -> float_type, {2048, 512, 1, 1}, {1, 2048, 1048576, 1048576}\n",
      "@1399 = transpose[dims={3, 2, 0, 1}](@1397) -> float_type, {2048, 512, 1, 1}, {1, 2048, 1048576, 1048576}\n",
      "@1400 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1396,@1399) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1401 = transpose[dims={0, 2, 3, 1}](@1400) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1402 = identity(@43) -> float_type, {2048}, {1}\n",
      "@1403 = transpose[dims={0, 3, 1, 2}](@1401) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1404 = broadcast[axis=1,dims={1, 2048, 7, 7}](@1402) -> float_type, {1, 2048, 7, 7}, {0, 1, 0, 0}\n",
      "@1405 = add(@1403,@1404) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1406 = transpose[dims={0, 2, 3, 1}](@1405) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1407 = identity(@42) -> float_type, {2048}, {1}\n",
      "@1408 = identity(@41) -> float_type, {2048}, {1}\n",
      "@1409 = identity(@40) -> float_type, {2048}, {1}\n",
      "@1410 = identity(@39) -> float_type, {2048}, {1}\n",
      "@1411 = unknown:FusedBatchNormV3(@1406,@1407,@1408,@1409,@1410) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1412 = unknown:AddV2(@1345,@1411) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1413 = transpose[dims={0, 3, 1, 2}](@1412) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1414 = relu(@1413) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1415 = transpose[dims={0, 2, 3, 1}](@1414) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1416 = transpose[dims={0, 2, 3, 1}](@38) -> float_type, {1, 2048, 512, 1}, {1048576, 512, 1, 1048576}\n",
      "@1417 = transpose[dims={0, 3, 1, 2}](@1416) -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@1418 = identity(@1417) -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@1419 = transpose[dims={0, 2, 3, 1}](@1418) -> float_type, {1, 2048, 512, 1}, {1048576, 512, 1, 1048576}\n",
      "@1420 = transpose[dims={0, 3, 1, 2}](@1415) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1421 = transpose[dims={0, 3, 1, 2}](@1419) -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@1422 = transpose[dims={3, 2, 0, 1}](@1421) -> float_type, {512, 2048, 1, 1}, {1, 512, 1048576, 1048576}\n",
      "@1423 = transpose[dims={3, 2, 0, 1}](@1421) -> float_type, {512, 2048, 1, 1}, {1, 512, 1048576, 1048576}\n",
      "@1424 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1420,@1423) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1425 = transpose[dims={0, 2, 3, 1}](@1424) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1426 = identity(@37) -> float_type, {512}, {1}\n",
      "@1427 = transpose[dims={0, 3, 1, 2}](@1425) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1428 = broadcast[axis=1,dims={1, 512, 7, 7}](@1426) -> float_type, {1, 512, 7, 7}, {0, 1, 0, 0}\n",
      "@1429 = add(@1427,@1428) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1430 = transpose[dims={0, 2, 3, 1}](@1429) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1431 = identity(@36) -> float_type, {512}, {1}\n",
      "@1432 = identity(@35) -> float_type, {512}, {1}\n",
      "@1433 = identity(@34) -> float_type, {512}, {1}\n",
      "@1434 = identity(@33) -> float_type, {512}, {1}\n",
      "@1435 = unknown:FusedBatchNormV3(@1430,@1431,@1432,@1433,@1434) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1436 = transpose[dims={0, 3, 1, 2}](@1435) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1437 = relu(@1436) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1438 = transpose[dims={0, 2, 3, 1}](@1437) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1439 = transpose[dims={0, 2, 3, 1}](@32) -> float_type, {3, 512, 512, 3}, {786432, 512, 1, 262144}\n",
      "@1440 = transpose[dims={0, 3, 1, 2}](@1439) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1441 = identity(@1440) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1442 = transpose[dims={0, 2, 3, 1}](@1441) -> float_type, {3, 512, 512, 3}, {786432, 512, 1, 262144}\n",
      "@1443 = transpose[dims={0, 3, 1, 2}](@1438) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1444 = transpose[dims={0, 3, 1, 2}](@1442) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1445 = transpose[dims={3, 2, 0, 1}](@1444) -> float_type, {512, 512, 3, 3}, {1, 512, 786432, 262144}\n",
      "@1446 = transpose[dims={3, 2, 0, 1}](@1444) -> float_type, {512, 512, 3, 3}, {1, 512, 786432, 262144}\n",
      "@1447 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1443,@1446) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1448 = transpose[dims={0, 2, 3, 1}](@1447) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1449 = identity(@31) -> float_type, {512}, {1}\n",
      "@1450 = transpose[dims={0, 3, 1, 2}](@1448) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1451 = broadcast[axis=1,dims={1, 512, 7, 7}](@1449) -> float_type, {1, 512, 7, 7}, {0, 1, 0, 0}\n",
      "@1452 = add(@1450,@1451) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1453 = transpose[dims={0, 2, 3, 1}](@1452) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1454 = identity(@30) -> float_type, {512}, {1}\n",
      "@1455 = identity(@29) -> float_type, {512}, {1}\n",
      "@1456 = identity(@28) -> float_type, {512}, {1}\n",
      "@1457 = identity(@27) -> float_type, {512}, {1}\n",
      "@1458 = unknown:FusedBatchNormV3(@1453,@1454,@1455,@1456,@1457) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1459 = transpose[dims={0, 3, 1, 2}](@1458) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1460 = relu(@1459) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1461 = transpose[dims={0, 2, 3, 1}](@1460) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1462 = transpose[dims={0, 2, 3, 1}](@26) -> float_type, {1, 512, 2048, 1}, {1048576, 2048, 1, 1048576}\n",
      "@1463 = transpose[dims={0, 3, 1, 2}](@1462) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1464 = identity(@1463) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1465 = transpose[dims={0, 2, 3, 1}](@1464) -> float_type, {1, 512, 2048, 1}, {1048576, 2048, 1, 1048576}\n",
      "@1466 = transpose[dims={0, 3, 1, 2}](@1461) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1467 = transpose[dims={0, 3, 1, 2}](@1465) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1468 = transpose[dims={3, 2, 0, 1}](@1467) -> float_type, {2048, 512, 1, 1}, {1, 2048, 1048576, 1048576}\n",
      "@1469 = transpose[dims={3, 2, 0, 1}](@1467) -> float_type, {2048, 512, 1, 1}, {1, 2048, 1048576, 1048576}\n",
      "@1470 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1466,@1469) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1471 = transpose[dims={0, 2, 3, 1}](@1470) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1472 = identity(@25) -> float_type, {2048}, {1}\n",
      "@1473 = transpose[dims={0, 3, 1, 2}](@1471) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1474 = broadcast[axis=1,dims={1, 2048, 7, 7}](@1472) -> float_type, {1, 2048, 7, 7}, {0, 1, 0, 0}\n",
      "@1475 = add(@1473,@1474) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1476 = transpose[dims={0, 2, 3, 1}](@1475) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1477 = identity(@24) -> float_type, {2048}, {1}\n",
      "@1478 = identity(@23) -> float_type, {2048}, {1}\n",
      "@1479 = identity(@22) -> float_type, {2048}, {1}\n",
      "@1480 = identity(@21) -> float_type, {2048}, {1}\n",
      "@1481 = unknown:FusedBatchNormV3(@1476,@1477,@1478,@1479,@1480) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1482 = unknown:AddV2(@1415,@1481) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1483 = transpose[dims={0, 3, 1, 2}](@1482) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1484 = relu(@1483) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1485 = transpose[dims={0, 2, 3, 1}](@1484) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1486 = transpose[dims={0, 2, 3, 1}](@20) -> float_type, {1, 2048, 512, 1}, {1048576, 512, 1, 1048576}\n",
      "@1487 = transpose[dims={0, 3, 1, 2}](@1486) -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@1488 = identity(@1487) -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@1489 = transpose[dims={0, 2, 3, 1}](@1488) -> float_type, {1, 2048, 512, 1}, {1048576, 512, 1, 1048576}\n",
      "@1490 = transpose[dims={0, 3, 1, 2}](@1485) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1491 = transpose[dims={0, 3, 1, 2}](@1489) -> float_type, {1, 1, 2048, 512}, {1048576, 1048576, 512, 1}\n",
      "@1492 = transpose[dims={3, 2, 0, 1}](@1491) -> float_type, {512, 2048, 1, 1}, {1, 512, 1048576, 1048576}\n",
      "@1493 = transpose[dims={3, 2, 0, 1}](@1491) -> float_type, {512, 2048, 1, 1}, {1, 512, 1048576, 1048576}\n",
      "@1494 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1490,@1493) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1495 = transpose[dims={0, 2, 3, 1}](@1494) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1496 = identity(@19) -> float_type, {512}, {1}\n",
      "@1497 = transpose[dims={0, 3, 1, 2}](@1495) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1498 = broadcast[axis=1,dims={1, 512, 7, 7}](@1496) -> float_type, {1, 512, 7, 7}, {0, 1, 0, 0}\n",
      "@1499 = add(@1497,@1498) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1500 = transpose[dims={0, 2, 3, 1}](@1499) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1501 = identity(@18) -> float_type, {512}, {1}\n",
      "@1502 = identity(@17) -> float_type, {512}, {1}\n",
      "@1503 = identity(@16) -> float_type, {512}, {1}\n",
      "@1504 = identity(@15) -> float_type, {512}, {1}\n",
      "@1505 = unknown:FusedBatchNormV3(@1500,@1501,@1502,@1503,@1504) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1506 = transpose[dims={0, 3, 1, 2}](@1505) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1507 = relu(@1506) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1508 = transpose[dims={0, 2, 3, 1}](@1507) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1509 = transpose[dims={0, 2, 3, 1}](@14) -> float_type, {3, 512, 512, 3}, {786432, 512, 1, 262144}\n",
      "@1510 = transpose[dims={0, 3, 1, 2}](@1509) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1511 = identity(@1510) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1512 = transpose[dims={0, 2, 3, 1}](@1511) -> float_type, {3, 512, 512, 3}, {786432, 512, 1, 262144}\n",
      "@1513 = transpose[dims={0, 3, 1, 2}](@1508) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1514 = transpose[dims={0, 3, 1, 2}](@1512) -> float_type, {3, 3, 512, 512}, {786432, 262144, 512, 1}\n",
      "@1515 = transpose[dims={3, 2, 0, 1}](@1514) -> float_type, {512, 512, 3, 3}, {1, 512, 786432, 262144}\n",
      "@1516 = transpose[dims={3, 2, 0, 1}](@1514) -> float_type, {512, 512, 3, 3}, {1, 512, 786432, 262144}\n",
      "@1517 = convolution[padding={1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=1](@1513,@1516) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1518 = transpose[dims={0, 2, 3, 1}](@1517) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1519 = identity(@13) -> float_type, {512}, {1}\n",
      "@1520 = transpose[dims={0, 3, 1, 2}](@1518) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1521 = broadcast[axis=1,dims={1, 512, 7, 7}](@1519) -> float_type, {1, 512, 7, 7}, {0, 1, 0, 0}\n",
      "@1522 = add(@1520,@1521) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1523 = transpose[dims={0, 2, 3, 1}](@1522) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1524 = identity(@12) -> float_type, {512}, {1}\n",
      "@1525 = identity(@11) -> float_type, {512}, {1}\n",
      "@1526 = identity(@10) -> float_type, {512}, {1}\n",
      "@1527 = identity(@9) -> float_type, {512}, {1}\n",
      "@1528 = unknown:FusedBatchNormV3(@1523,@1524,@1525,@1526,@1527) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1529 = transpose[dims={0, 3, 1, 2}](@1528) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1530 = relu(@1529) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1531 = transpose[dims={0, 2, 3, 1}](@1530) -> float_type, {1, 7, 7, 512}, {25088, 7, 1, 49}\n",
      "@1532 = transpose[dims={0, 2, 3, 1}](@8) -> float_type, {1, 512, 2048, 1}, {1048576, 2048, 1, 1048576}\n",
      "@1533 = transpose[dims={0, 3, 1, 2}](@1532) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1534 = identity(@1533) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1535 = transpose[dims={0, 2, 3, 1}](@1534) -> float_type, {1, 512, 2048, 1}, {1048576, 2048, 1, 1048576}\n",
      "@1536 = transpose[dims={0, 3, 1, 2}](@1531) -> float_type, {1, 512, 7, 7}, {25088, 49, 7, 1}\n",
      "@1537 = transpose[dims={0, 3, 1, 2}](@1535) -> float_type, {1, 1, 512, 2048}, {1048576, 1048576, 2048, 1}\n",
      "@1538 = transpose[dims={3, 2, 0, 1}](@1537) -> float_type, {2048, 512, 1, 1}, {1, 2048, 1048576, 1048576}\n",
      "@1539 = transpose[dims={3, 2, 0, 1}](@1537) -> float_type, {2048, 512, 1, 1}, {1, 2048, 1048576, 1048576}\n",
      "@1540 = convolution[padding={0, 0},stride={1, 1},dilation={1, 1},group=1,padding_mode=2](@1536,@1539) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1541 = transpose[dims={0, 2, 3, 1}](@1540) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1542 = identity(@7) -> float_type, {2048}, {1}\n",
      "@1543 = transpose[dims={0, 3, 1, 2}](@1541) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1544 = broadcast[axis=1,dims={1, 2048, 7, 7}](@1542) -> float_type, {1, 2048, 7, 7}, {0, 1, 0, 0}\n",
      "@1545 = add(@1543,@1544) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1546 = transpose[dims={0, 2, 3, 1}](@1545) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1547 = identity(@6) -> float_type, {2048}, {1}\n",
      "@1548 = identity(@5) -> float_type, {2048}, {1}\n",
      "@1549 = identity(@4) -> float_type, {2048}, {1}\n",
      "@1550 = identity(@3) -> float_type, {2048}, {1}\n",
      "@1551 = unknown:FusedBatchNormV3(@1546,@1547,@1548,@1549,@1550) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1552 = unknown:AddV2(@1485,@1551) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1553 = transpose[dims={0, 3, 1, 2}](@1552) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1554 = relu(@1553) -> float_type, {1, 2048, 7, 7}, {100352, 49, 7, 1}\n",
      "@1555 = transpose[dims={0, 2, 3, 1}](@1554) -> float_type, {1, 7, 7, 2048}, {100352, 7, 1, 49}\n",
      "@1556 = reduce_mean[axes={1, 2}](@1555) -> float_type, {1, 1, 1, 2048}, {2048, 2048, 2048, 1}\n",
      "@1557 = squeeze[axes={1, 2}](@1556) -> float_type, {1, 2048}, {2048, 1}\n",
      "@1558 = identity(@1) -> float_type, {2048, 1000}, {1000, 1}\n",
      "@1559 = dot[alpha=1,beta=1](@1557,@1558) -> float_type, {1, 1000}, {1000, 1}\n",
      "@1560 = identity(@0) -> float_type, {1000}, {1}\n",
      "@1561 = broadcast[axis=1,dims={1, 1000}](@1560) -> float_type, {1, 1000}, {0, 1}\n",
      "@1562 = add(@1559,@1561) -> float_type, {1, 1000}, {1000, 1}\n",
      "@1563 = softmax[axis=1](@1562) -> float_type, {1, 1000}, {1000, 1}\n",
      "@1564 = identity(@1563) -> float_type, {1, 1000}, {1000, 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "driver = \"/opt/rocm/bin/migraphx-driver\"\n",
    "command = \"read\"\n",
    "model_path = \"./frozen_models/{}_frozen_graph.pb\".format(MODEL_NAME)\n",
    "process = subprocess.run([driver, command, model_path], \n",
    "                         stdout=subprocess.PIPE, \n",
    "                         universal_newlines=True)\n",
    "\n",
    "print(process.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
